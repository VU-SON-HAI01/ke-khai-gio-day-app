# fun_tkb_timkiem.py
import streamlit as st
import pandas as pd
import re
import gspread
from google.oauth2.service_account import Credentials

# --- C√ÅC H√ÄM K·∫æT N·ªêI V√Ä ƒê·ªåC GOOGLE SHEETS ---

@st.cache_resource
def connect_to_gsheet():
    """
    K·∫øt n·ªëi t·ªõi Google Sheets s·ª≠ d·ª•ng Service Account credentials t·ª´ st.secrets.
    """
    try:
        creds_dict = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi Google Sheets: {e}")
        return None

@st.cache_data(ttl=60)
def get_all_data_sheets(_client, spreadsheet_id):
    """
    L·∫•y danh s√°ch t·∫•t c·∫£ c√°c sheet d·ªØ li·ªáu (b·∫Øt ƒë·∫ßu b·∫±ng "DATA_").
    """
    if not _client: return []
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        return [s.title for s in spreadsheet.worksheets() if s.title.startswith("DATA_")]
    except Exception as e:
        st.error(f"L·ªói khi l·∫•y danh s√°ch sheet: {e}"); return []

@st.cache_data(ttl=60)
def load_data_from_gsheet(_client, spreadsheet_id, sheet_name):
    """
    T·∫£i d·ªØ li·ªáu t·ª´ m·ªôt sheet c·ª• th·ªÉ v√† chuy·ªÉn th√†nh DataFrame.
    """
    if not _client or not sheet_name: return pd.DataFrame()
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet(sheet_name)
        df = pd.DataFrame(worksheet.get_all_records())
        # ƒê·∫£m b·∫£o c√°c c·ªôt s·ªë c√≥ ƒë√∫ng ki·ªÉu d·ªØ li·ªáu ƒë·ªÉ s·∫Øp x·∫øp
        for col in ['Th·ª©', 'Ti·∫øt']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        return df
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ sheet '{sheet_name}': {e}"); return pd.DataFrame()

@st.cache_data(ttl=300) # Cache for 5 minutes
def load_all_data_and_get_dates(_client, spreadsheet_id):
    """
    T·∫£i d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ c√°c sheet "DATA_*", h·ª£p nh·∫•t ch√∫ng,
    v√† tr·∫£ v·ªÅ DataFrame t·ªïng h·ª£p c√πng danh s√°ch c√°c ng√†y √°p d·ª•ng duy nh·∫•t.
    """
    if not _client:
        return pd.DataFrame(), []

    try:
        sheet_list = get_all_data_sheets(_client, spreadsheet_id)
        if not sheet_list:
            return pd.DataFrame(), []

        all_dfs = []
        for sheet_name in sheet_list:
            df = load_data_from_gsheet(_client, spreadsheet_id, sheet_name)
            if not df.empty:
                all_dfs.append(df)

        if not all_dfs:
            return pd.DataFrame(), []

        combined_df = pd.concat(all_dfs, ignore_index=True)

        if 'Ng√†y √°p d·ª•ng' in combined_df.columns:
            # 1. Chuy·ªÉn ƒë·ªïi c·ªôt 'Ng√†y √°p d·ª•ng' sang ki·ªÉu datetime ƒë·ªÉ x·ª≠ l√Ω
            valid_dates_series = pd.to_datetime(combined_df['Ng√†y √°p d·ª•ng'], dayfirst=True, errors='coerce')

            # 2. T·∫°o danh s√°ch ng√†y cho b·ªô l·ªçc t·ª´ c√°c ng√†y h·ª£p l·ªá
            date_list = sorted(valid_dates_series.dropna().dt.strftime('%d/%m/%Y').unique())

            # 3. Chu·∫©n h√≥a c·ªôt 'Ng√†y √°p d·ª•ng' trong DataFrame ch√≠nh v·ªÅ c√πng ƒë·ªãnh d·∫°ng
            combined_df['Ng√†y √°p d·ª•ng'] = valid_dates_series.dt.strftime('%d/%m/%Y')

        else:
            date_list = []

        return combined_df, date_list

    except Exception as e:
        st.error(f"L·ªói khi t·∫£i v√† h·ª£p nh·∫•t d·ªØ li·ªáu: {e}")
        return pd.DataFrame(), []


# --- H√ÄM HI·ªÇN TH·ªä CHI TI·∫æT L·ªäCH H·ªåC (D√ôNG CHUNG) ---
def render_schedule_details(schedule_df, mode='class'):
    """H√†m chung ƒë·ªÉ hi·ªÉn th·ªã chi ti·∫øt l·ªãch h·ªçc ho·∫∑c l·ªãch d·∫°y."""
    green_color = "#00FF00"
    number_to_day_map = {2: 'TH·ª® HAI', 3: 'TH·ª® BA', 4: 'TH·ª® T∆Ø', 5: 'TH·ª® NƒÇM', 6: 'TH·ª® S√ÅU', 7: 'TH·ª® B·∫¢Y'}
    schedule_df['Th·ª© ƒê·∫ßy ƒê·ªß'] = schedule_df['Th·ª©'].map(number_to_day_map)
    
    day_order = list(number_to_day_map.values()); session_order = ['S√°ng', 'Chi·ªÅu']
    schedule_df['Th·ª© ƒê·∫ßy ƒê·ªß'] = pd.Categorical(schedule_df['Th·ª© ƒê·∫ßy ƒê·ªß'], categories=day_order, ordered=True)
    schedule_df['Bu·ªïi'] = pd.Categorical(schedule_df['Bu·ªïi'], categories=session_order, ordered=True)
    schedule_sorted = schedule_df.sort_values(by=['Th·ª© ƒê·∫ßy ƒê·ªß', 'Bu·ªïi', 'Ti·∫øt'])

    first_day = True
    for day, day_group in schedule_sorted.groupby('Th·ª© ƒê·∫ßy ƒê·ªß', observed=False):
        # B·ªè qua v√† kh√¥ng hi·ªÉn th·ªã nh·ªØng ng√†y kh√¥ng c√≥ m√¥n h·ªçc
        if day_group['M√¥n h·ªçc'].dropna().empty:
            continue

        if not first_day:
            st.markdown("---") 

        st.markdown(f"##### **{day}**") 
        first_day = False

        can_consolidate = False
        if set(day_group['Bu·ªïi'].unique()) == {'S√°ng', 'Chi·ªÅu'}:
            sang_subjects = day_group[day_group['Bu·ªïi'] == 'S√°ng'][['M√¥n h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng h·ªçc', 'L·ªõp']].drop_duplicates()
            chieu_subjects = day_group[day_group['Bu·ªïi'] == 'Chi·ªÅu'][['M√¥n h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng h·ªçc', 'L·ªõp']].drop_duplicates()
            if len(sang_subjects) == 1 and sang_subjects.equals(chieu_subjects): can_consolidate = True

        if can_consolidate:
            st.markdown(f'<p style="color:#17a2b8; font-weight:bold;">C·∫¢ NG√ÄY</p>', unsafe_allow_html=True)
            subject_info = sang_subjects.iloc[0]
            tiet_str = ", ".join(sorted(day_group['Ti·∫øt'].astype(str).tolist(), key=int))
            
            details = []
            details.append(f"üìñ **M√¥n:** <span style='color:{green_color};'>{subject_info['M√¥n h·ªçc']}</span>")
            details.append(f"‚è∞ **Ti·∫øt:** <span style='color:{green_color};'>{tiet_str}</span>")
            
            if mode == 'class':
                if subject_info['Gi√°o vi√™n BM']: details.append(f"üßë‚Äçüíº **GV:** <span style='color:{green_color};'>{subject_info['Gi√°o vi√™n BM']}</span>")
            else: # mode == 'teacher'
                if subject_info['L·ªõp']: details.append(f"üìù **L·ªõp:** <span style='color:{green_color};'>{subject_info['L·ªõp']}</span>")
            
            if subject_info['Ph√≤ng h·ªçc']: details.append(f"üè§ **Ph√≤ng:** <span style='color:{green_color};'>{subject_info['Ph√≤ng h·ªçc']}</span>")
            
            details_html = "<br>".join(f"&nbsp;&nbsp;{item}" for item in details)
            st.markdown(f"<div>{details_html}</div>", unsafe_allow_html=True)

        else:
            for session, session_group in day_group.groupby('Bu·ªïi', observed=False):
                if session_group['M√¥n h·ªçc'].dropna().empty: continue
                
                color = "#28a745" if session == "S√°ng" else "#dc3545"
                st.markdown(f'<p style="color:{color}; font-weight:bold;">{session.upper()}</p>', unsafe_allow_html=True)
                
                subjects_in_session = {}
                for _, row in session_group.iterrows():
                    if pd.notna(row['M√¥n h·ªçc']) and row['M√¥n h·ªçc'].strip():
                        key = (row['M√¥n h·ªçc'], row['Gi√°o vi√™n BM'], row['Ph√≤ng h·ªçc'], row['Ghi ch√∫'], row.get('Ng√†y √°p d·ª•ng', ''), row.get('L·ªõp', ''))
                        if key not in subjects_in_session: subjects_in_session[key] = []
                        subjects_in_session[key].append(str(row['Ti·∫øt']))
                
                if not subjects_in_session:
                    st.markdown("&nbsp;&nbsp;‚ú®Ngh·ªâ")
                else:
                    for (subject, gv, phong, ghi_chu, ngay_ap_dung, lop), tiet_list in subjects_in_session.items():
                        tiet_str = ", ".join(sorted(tiet_list, key=int))
                        
                        details = []
                        details.append(f"üìñ **M√¥n:** <span style='color:{green_color};'>{subject}</span>")
                        details.append(f"‚è∞ **Ti·∫øt:** <span style='color:{green_color};'>{tiet_str}</span>")
                        
                        if mode == 'class':
                            if gv: details.append(f"üßë‚Äçüíº **GV:** <span style='color:{green_color};'>{gv}</span>")
                        else: # mode == 'teacher'
                            if lop: details.append(f"üìù **L·ªõp:** <span style='color:{green_color};'>{lop}</span>")
                        
                        if phong: details.append(f"üè§ **Ph√≤ng:** <span style='color:{green_color};'>{phong}</span>")

                        ghi_chu_part = ""
                        if ghi_chu and "h·ªçc t·ª´" in ghi_chu.lower():
                            date_match = re.search(r'(\d+/\d+)', ghi_chu)
                            if date_match:
                                ghi_chu_part = f"üîú **B·∫Øt ƒë·∫ßu h·ªçc t·ª´:** <span style='color:{green_color};'>\"{date_match.group(1)}\"</span>"
                        elif ngay_ap_dung and str(ngay_ap_dung).strip():
                            ghi_chu_part = f"üîú **B·∫Øt ƒë·∫ßu h·ªçc t·ª´:** <span style='color:{green_color};'>\"{ngay_ap_dung}\"</span>"
                        
                        if ghi_chu_part:
                            details.append(ghi_chu_part)

                        details_html = "<br>".join(f"&nbsp;&nbsp;{item}" for item in details)
                        st.markdown(f"<div>{details_html}</div><br>", unsafe_allow_html=True)
