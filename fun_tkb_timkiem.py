# fun_tkb_timkiem.py
import streamlit as st
import pandas as pd
import re
import gspread
from google.oauth2.service_account import Credentials

# --- C√ÅC H√ÄM K·∫æT N·ªêI V√Ä ƒê·ªåC GOOGLE SHEETS ---

@st.cache_resource
def connect_to_gsheet():
    """
    K·∫øt n·ªëi t·ªõi Google Sheets s·ª≠ d·ª•ng Service Account credentials t·ª´ st.secrets.
    """
    try:
        creds_dict = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi Google Sheets: {e}")
        return None

@st.cache_data(ttl=60)
def get_all_data_sheets(_client, spreadsheet_id):
    """
    L·∫•y danh s√°ch t·∫•t c·∫£ c√°c sheet d·ªØ li·ªáu (b·∫Øt ƒë·∫ßu b·∫±ng "DATA_").
    """
    if not _client: return []
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        return [s.title for s in spreadsheet.worksheets() if s.title.startswith("DATA_")]
    except Exception as e:
        st.error(f"L·ªói khi l·∫•y danh s√°ch sheet: {e}"); return []

@st.cache_data(ttl=60)
def load_data_from_gsheet(_client, spreadsheet_id, sheet_name):
    """
    T·∫£i d·ªØ li·ªáu t·ª´ m·ªôt sheet c·ª• th·ªÉ v√† chuy·ªÉn th√†nh DataFrame.
    """
    if not _client or not sheet_name: return pd.DataFrame()
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet(sheet_name)
        df = pd.DataFrame(worksheet.get_all_records())
        # ƒê·∫£m b·∫£o c√°c c·ªôt s·ªë c√≥ ƒë√∫ng ki·ªÉu d·ªØ li·ªáu ƒë·ªÉ s·∫Øp x·∫øp
        for col in ['Th·ª©', 'Ti·∫øt']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        return df
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ sheet '{sheet_name}': {e}"); return pd.DataFrame()

@st.cache_data(ttl=300) # Cache for 5 minutes
def load_all_data_and_get_dates(_client, spreadsheet_id):
    """
    T·∫£i d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ c√°c sheet "DATA_*", h·ª£p nh·∫•t ch√∫ng,
    v√† tr·∫£ v·ªÅ DataFrame t·ªïng h·ª£p c√πng danh s√°ch c√°c ng√†y √°p d·ª•ng duy nh·∫•t.
    """
    if not _client:
        return pd.DataFrame(), []

    try:
        sheet_list = get_all_data_sheets(_client, spreadsheet_id)
        if not sheet_list:
            return pd.DataFrame(), []

        all_dfs = []
        for sheet_name in sheet_list:
            df = load_data_from_gsheet(_client, spreadsheet_id, sheet_name)
            if not df.empty:
                all_dfs.append(df)

        if not all_dfs:
            return pd.DataFrame(), []

        combined_df = pd.concat(all_dfs, ignore_index=True)

        if 'Ng√†y √°p d·ª•ng' in combined_df.columns:
            # L·∫•y t·∫•t c·∫£ c√°c gi√° tr·ªã kh√¥ng r·ªóng v√† duy nh·∫•t t·ª´ c·ªôt 'Ng√†y √°p d·ª•ng'
            dates = combined_df['Ng√†y √°p d·ª•ng'].dropna().astype(str).unique()

            # *** PH·∫¶N ƒê∆Ø·ª¢C C·∫¨P NH·∫¨T ***
            # S·ª≠ d·ª•ng pd.to_datetime ƒë·ªÉ chuy·ªÉn ƒë·ªïi linh ho·∫°t nhi·ªÅu ƒë·ªãnh d·∫°ng ng√†y.
            # errors='coerce' s·∫Ω chuy·ªÉn c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá th√†nh NaT (Not a Time).
            valid_dates = pd.to_datetime(dates, dayfirst=True, errors='coerce')
            
            # L·ªçc b·ªè c√°c gi√° tr·ªã NaT, s·∫Øp x·∫øp v√† chuy·ªÉn v·ªÅ ƒë·ªãnh d·∫°ng chu·ªói dd/mm/yyyy
            sorted_dates = pd.Series(valid_dates).dropna().sort_values()
            date_list = sorted_dates.strftime('%d/%m/%Y').tolist()
        else:
            date_list = []

        return combined_df, date_list

    except Exception as e:
        st.error(f"L·ªói khi t·∫£i v√† h·ª£p nh·∫•t d·ªØ li·ªáu: {e}")
        return pd.DataFrame(), []


# --- H√ÄM HI·ªÇN TH·ªä CHI TI·∫æT L·ªäCH H·ªåC (D√ôNG CHUNG) ---
def render_schedule_details(schedule_df, mode='class'):
    """H√†m chung ƒë·ªÉ hi·ªÉn th·ªã chi ti·∫øt l·ªãch h·ªçc ho·∫∑c l·ªãch d·∫°y."""
    green_color = "#00FF00"
    number_to_day_map = {2: 'TH·ª® HAI', 3: 'TH·ª® BA', 4: 'TH·ª® T∆Ø', 5: 'TH·ª® NƒÇM', 6: 'TH·ª® S√ÅU', 7: 'TH·ª® B·∫¢Y'}
    schedule_df['Th·ª© ƒê·∫ßy ƒê·ªß'] = schedule_df['Th·ª©'].map(number_to_day_map)
    
    day_order = list(number_to_day_map.values()); session_order = ['S√°ng', 'Chi·ªÅu']
    schedule_df['Th·ª© ƒê·∫ßy ƒê·ªß'] = pd.Categorical(schedule_df['Th·ª© ƒê·∫ßy ƒê·ªß'], categories=day_order, ordered=True)
    schedule_df['Bu·ªïi'] = pd.Categorical(schedule_df['Bu·ªïi'], categories=session_order, ordered=True)
    schedule_sorted = schedule_df.sort_values(by=['Th·ª© ƒê·∫ßy ƒê·ªß', 'Bu·ªïi', 'Ti·∫øt'])

    for day, day_group in schedule_sorted.groupby('Th·ª© ƒê·∫ßy ƒê·ªß', observed=False):
        with st.expander(f"**{day}**"):
            can_consolidate = False
            if set(day_group['Bu·ªïi'].unique()) == {'S√°ng', 'Chi·ªÅu'}:
                sang_subjects = day_group[day_group['Bu·ªïi'] == 'S√°ng'][['M√¥n h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng h·ªçc', 'L·ªõp']].drop_duplicates()
                chieu_subjects = day_group[day_group['Bu·ªïi'] == 'Chi·ªÅu'][['M√¥n h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng h·ªçc', 'L·ªõp']].drop_duplicates()
                if len(sang_subjects) == 1 and sang_subjects.equals(chieu_subjects): can_consolidate = True

            if can_consolidate:
                col1, col2 = st.columns([1, 6])
                with col1: st.markdown(f'<p style="color:#17a2b8; font-weight:bold;">C·∫¢ NG√ÄY</p>', unsafe_allow_html=True)
                with col2:
                    subject_info = sang_subjects.iloc[0]
                    tiet_str = ", ".join(sorted(day_group['Ti·∫øt'].astype(str).tolist(), key=int))
                    tiet_part = f"‚è∞ **Ti·∫øt:** <span style='color:{green_color};'>{tiet_str}</span>"
                    subject_part = f"üìñ **M√¥n:** <span style='color:{green_color};'>{subject_info['M√¥n h·ªçc']}</span>"
                    phong_part = f"üè§ **Ph√≤ng:** <span style='color:{green_color};'>{subject_info['Ph√≤ng h·ªçc']}</span>" if subject_info['Ph√≤ng h·ªçc'] else ""
                    
                    if mode == 'class':
                        context_part = f"üßë‚Äçüíº **GV:** <span style='color:{green_color};'>{subject_info['Gi√°o vi√™n BM']}</span>" if subject_info['Gi√°o vi√™n BM'] else ""
                    else: # mode == 'teacher'
                        context_part = f"üìù **L·ªõp:** <span style='color:{green_color};'>{subject_info['L·ªõp']}</span>" if subject_info['L·ªõp'] else ""
                    
                    all_parts = [p for p in [tiet_part, subject_part, context_part, phong_part] if p]
                    st.markdown("&nbsp;&nbsp;".join(all_parts), unsafe_allow_html=True)
            else:
                for session, session_group in day_group.groupby('Bu·ªïi', observed=False):
                    if session_group.empty: continue
                    col1, col2 = st.columns([1, 6])
                    with col1:
                        color = "#28a745" if session == "S√°ng" else "#dc3545"
                        st.markdown(f'<p style="color:{color}; font-weight:bold;">{session.upper()}</p>', unsafe_allow_html=True)
                    with col2:
                        subjects_in_session = {}
                        for _, row in session_group.iterrows():
                            if pd.notna(row['M√¥n h·ªçc']) and row['M√¥n h·ªçc'].strip():
                                key = (row['M√¥n h·ªçc'], row['Gi√°o vi√™n BM'], row['Ph√≤ng h·ªçc'], row['Ghi ch√∫'], row.get('Ng√†y √°p d·ª•ng', ''), row.get('L·ªõp', ''))
                                if key not in subjects_in_session: subjects_in_session[key] = []
                                subjects_in_session[key].append(str(row['Ti·∫øt']))
                        if not subjects_in_session:
                            st.markdown("‚ú®Ngh·ªâ")
                        else:
                            for (subject, gv, phong, ghi_chu, ngay_ap_dung, lop), tiet_list in subjects_in_session.items():
                                tiet_str = ", ".join(sorted(tiet_list, key=int))
                                tiet_part = f"‚è∞ **Ti·∫øt:** <span style='color:{green_color};'>{tiet_str}</span>"
                                subject_part = f"üìñ **M√¥n:** <span style='color:{green_color};'>{subject}</span>"
                                phong_part = f"üè§ **Ph√≤ng:** <span style='color:{green_color};'>{phong}</span>" if phong else ""
                                
                                if mode == 'class':
                                    context_part = f"üßë‚Äçüíº **GV:** <span style='color:{green_color};'>{gv}</span>" if gv else ""
                                else: # mode == 'teacher'
                                    context_part = f"üìù **L·ªõp:** <span style='color:{green_color};'>{lop}</span>" if lop else ""

                                ghi_chu_part = ""
                                if ghi_chu and "h·ªçc t·ª´" in ghi_chu.lower():
                                    date_match = re.search(r'(\d+/\d+)', ghi_chu)
                                    if date_match:
                                        ghi_chu_part = f"üîú **B·∫Øt ƒë·∫ßu h·ªçc t·ª´:** <span style='color:{green_color};'>\"{date_match.group(1)}\"</span>"
                                elif ngay_ap_dung and str(ngay_ap_dung).strip():
                                    ghi_chu_part = f"üîú **B·∫Øt ƒë·∫ßu h·ªçc t·ª´:** <span style='color:{green_color};'>\"{ngay_ap_dung}\"</span>"

                                all_parts = [p for p in [tiet_part, subject_part, context_part, phong_part, ghi_chu_part] if p]
                                st.markdown("&nbsp;&nbsp;".join(all_parts), unsafe_allow_html=True)
