# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
import streamlit as st
import pandas as pd
import openpyxl
import io
import re
import gspread
from google.oauth2.service_account import Credentials

# --- C√ÅC H√ÄM K·∫æT N·ªêI GOOGLE SHEETS ---

@st.cache_resource
def connect_to_gsheet():
    """
    K·∫øt n·ªëi t·ªõi Google Sheets s·ª≠ d·ª•ng Service Account credentials t·ª´ st.secrets.
    """
    try:
        creds_dict = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi Google Sheets: {e}")
        return None

@st.cache_data(ttl=600)
def get_teacher_mapping(_gsheet_client, spreadsheet_id):
    """
    L·∫•y d·ªØ li·ªáu √°nh x·∫° t√™n gi√°o vi√™n t·ª´ Google Sheet.
    """
    if _gsheet_client is None:
        return {}
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("THONG_TIN_GV")
        df = pd.DataFrame(worksheet.get_all_records())
        
        required_cols = ["Ten_viet_tat", "Ho_ten_gv"]
        if not all(col in df.columns for col in required_cols):
            st.error(f"L·ªói: Sheet 'THONG_TIN_GV' b·ªã thi·∫øu c·ªôt b·∫Øt bu·ªôc.")
            return {}
            
        mapping = pd.Series(df.Ho_ten_gv.values, index=df.Ten_viet_tat.str.strip()).to_dict()
        return mapping
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu gi√°o vi√™n: {e}")
        return {}

def save_df_to_gsheet(client, spreadsheet_id, sheet_name, df):
    """
    L∆∞u m·ªôt DataFrame v√†o m·ªôt sheet c·ª• th·ªÉ c·ªßa Google Sheet.
    """
    try:
        spreadsheet = client.open_by_key(spreadsheet_id)
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
            worksheet.clear()
        except gspread.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows="1", cols="1")

        data_to_upload = [df.columns.values.tolist()] + df.values.tolist()
        worksheet.update(data_to_upload, 'A1')
        return True, None
    except Exception as e:
        return False, str(e)

# --- C√ÅC H√ÄM X·ª¨ L√ù EXCEL ---

def extract_schedule_from_excel(worksheet):
    """
    Tr√≠ch xu·∫•t d·ªØ li·ªáu TKB t·ª´ m·ªôt worksheet, t·ª± ƒë·ªông t√¨m v√πng d·ªØ li·ªáu, 
    x·ª≠ l√Ω √¥ g·ªôp v√† x·ª≠ l√Ω ti√™u ƒë·ªÅ ƒëa d√≤ng.
    """
    start_row, start_col = -1, -1
    for r_idx, row in enumerate(worksheet.iter_rows(min_row=1, max_row=10), 1):
        for c_idx, cell in enumerate(row, 1):
            if cell.value and "th·ª©" in str(cell.value).lower():
                start_row, start_col = r_idx, c_idx
                break
        if start_row != -1:
            break
            
    if start_row == -1:
        st.error("Kh√¥ng t√¨m th·∫•y √¥ ti√™u ƒë·ªÅ 'Th·ª©' trong 10 d√≤ng ƒë·∫ßu ti√™n c·ªßa file.")
        return None

    last_row = start_row
    tiet_col_index = start_col + 2 
    for r_idx in range(worksheet.max_row, start_row - 1, -1):
        cell_value = worksheet.cell(row=r_idx, column=tiet_col_index).value
        if cell_value is not None and isinstance(cell_value, (int, float)):
            last_row = r_idx
            break

    last_col = start_col
    for row in worksheet.iter_rows(min_row=start_row, max_row=last_row):
        for cell in row:
            if cell.value is not None and cell.column > last_col:
                last_col = cell.column

    merged_values = {}
    for merged_range in worksheet.merged_cells.ranges:
        top_left_cell = worksheet.cell(row=merged_range.min_row, column=merged_range.min_col)
        for row_ in range(merged_range.min_row, merged_range.max_row + 1):
            for col_ in range(merged_range.min_col, merged_range.max_col + 1):
                merged_values[(row_, col_)] = top_left_cell.value

    day_to_number_map = {'HAI': 2, 'BA': 3, 'T∆Ø': 4, 'NƒÇM': 5, 'S√ÅU': 6, 'B·∫¢Y': 7}
    data = []
    for r_idx in range(start_row, last_row + 1):
        row_data = [
            merged_values.get((r_idx, c_idx), worksheet.cell(row=r_idx, column=c_idx).value)
            for c_idx in range(start_col, last_col + 1)
        ]
        if r_idx > start_row:
            clean_day = re.sub(r'\s+', '', str(row_data[0] or '')).strip().upper()
            row_data[0] = day_to_number_map.get(clean_day, row_data[0])
        data.append(row_data)

    if not data: return None

    header_level1 = data[0]
    header_level2 = data[1]
    
    filled_header_level1 = []
    last_val = ""
    for val in header_level1:
        if val is not None and str(val).strip() != '':
            last_val = val
        filled_header_level1.append(last_val)

    combined_headers = [
        f"{str(h1 or '').strip()}___{str(h2 or '').strip()}" if i >= 3 else str(h1 or '').strip()
        for i, (h1, h2) in enumerate(zip(filled_header_level1, header_level2))
    ]

    df = pd.DataFrame(data[2:], columns=combined_headers)
    return df

def map_and_prefix_teacher_name(short_name, mapping):
    short_name_clean = str(short_name or '').strip()
    if not short_name_clean: return ''
    full_name = mapping.get(short_name_clean)
    if full_name:
        if short_name_clean.startswith('T.'): return f"Th·∫ßy {full_name}"
        if short_name_clean.startswith('C.'): return f"C√¥ {full_name}"
        return full_name
    return short_name_clean

def transform_to_database_format(df_wide, teacher_mapping):
    """
    Chuy·ªÉn ƒë·ªïi DataFrame d·∫°ng r·ªông sang d√†i, x·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát cho m√¥n h·ªçc.
    """
    id_vars = ['Th·ª©', 'Bu·ªïi', 'Ti·∫øt']
    df_long = pd.melt(df_wide, id_vars=id_vars, var_name='L·ªõp_Raw', value_name='Chi ti·∫øt M√¥n h·ªçc')
    df_long.dropna(subset=['Chi ti·∫øt M√¥n h·ªçc'], inplace=True)
    df_long = df_long[df_long['Chi ti·∫øt M√¥n h·ªçc'].astype(str).str.strip() != '']
    
    def parse_subject_details_custom(cell_text):
        # 1. L√†m s·∫°ch chu·ªói ban ƒë·∫ßu
        clean_text = str(cell_text).replace('\n', ' ').strip()
        clean_text = re.sub(r'\s{2,}', ' ', clean_text) # Thay th·∫ø 2+ kho·∫£ng tr·∫Øng b·∫±ng 1

        # 2. T√°ch ph·∫ßn ghi ch√∫
        ghi_chu = ""
        note_match = re.search(r'(H·ªçc t·ª´.*)', clean_text, re.IGNORECASE)
        if note_match:
            ghi_chu = note_match.group(1).strip()
            clean_text = clean_text.replace(ghi_chu, '').strip()
        
        # 3. X·ª≠ l√Ω ph·∫ßn c√≤n l·∫°i c·ªßa chu·ªói
        remaining_text = clean_text
        
        if "THPT" in remaining_text.upper():
            return ("H·ªåC TKB VƒÇN H√ìA THPT", "", "", ghi_chu)
        
        match = re.search(r'^(.*?)\s*\((.*?)\s*-\s*(.*?)\)$', remaining_text)
        if match:
            mon_hoc = match.group(1).strip()
            phong_hoc = match.group(2).strip()
            giao_vien = match.group(3).strip()
            # Ki·ªÉm tra xem c√≥ ghi ch√∫ sau d·∫•u ')' kh√¥ng
            after_paren_text = remaining_text[match.end():].strip()
            if after_paren_text:
                ghi_chu = f"{ghi_chu} {after_paren_text}".strip()
            return (mon_hoc, phong_hoc, giao_vien, ghi_chu)
        
        return (remaining_text, "", "", ghi_chu)

    parsed_cols = df_long['Chi ti·∫øt M√¥n h·ªçc'].apply(parse_subject_details_custom)
    mh_extracted = pd.DataFrame(parsed_cols.tolist(), index=df_long.index, columns=['M√¥n h·ªçc', 'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 'Ghi ch√∫'])
    
    header_parts = df_long['L·ªõp_Raw'].str.split('___', expand=True)
    lop_extracted = header_parts[0].str.extract(r'^(.*?)\s*(?:\((\d+)\))?$')
    lop_extracted.columns = ['L·ªõp', 'Sƒ© s·ªë']
    cn_extracted = header_parts[1].str.extract(r'^(.*?)\s*-\s*(.*?)(?:\s*\((.*?)\))?$')
    cn_extracted.columns = ['Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 'L·ªõp VHPT']
    
    df_final = pd.concat([
        df_long[['Th·ª©', 'Bu·ªïi', 'Ti·∫øt']].reset_index(drop=True),
        lop_extracted.reset_index(drop=True),
        cn_extracted.reset_index(drop=True),
        mh_extracted.reset_index(drop=True)
    ], axis=1)

    df_final['Tr√¨nh ƒë·ªô'] = df_final['L·ªõp'].apply(lambda x: 'Cao ƒë·∫≥ng' if 'C.' in str(x) else ('Trung C·∫•p' if 'T.' in str(x) else ''))
    df_final.fillna('', inplace=True)

    if teacher_mapping:
        df_final['Gi√°o vi√™n CN'] = df_final['Gi√°o vi√™n CN'].apply(lambda n: map_and_prefix_teacher_name(n, teacher_mapping))
        df_final['Gi√°o vi√™n BM'] = df_final['Gi√°o vi√™n BM'].apply(lambda n: map_and_prefix_teacher_name(n, teacher_mapping))
    
    final_cols = ['Th·ª©', 'Bu·ªïi', 'Ti·∫øt', 'L·ªõp', 'Sƒ© s·ªë', 'Tr√¨nh ƒë·ªô', 'M√¥n h·ªçc', 'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 'L·ªõp VHPT', 'Ghi ch√∫']
    df_final = df_final[final_cols]
    
    return df_final


# --- Giao di·ªán ·ª©ng d·ª•ng Streamlit ---

st.set_page_config(page_title="Tr√≠ch xu·∫•t v√† Truy v·∫•n TKB", layout="wide")
st.title("üìä Tr√≠ch xu·∫•t v√† Truy v·∫•n Th·ªùi Kh√≥a Bi·ªÉu")
st.write("T·∫£i file Excel TKB, ·ª©ng d·ª•ng s·∫Ω t·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi, cho ph√©p tra c·ª©u v√† l∆∞u tr·ªØ d·ªØ li·ªáu.")

with st.expander("üí° H∆∞·ªõng d·∫´n & C·∫•u h√¨nh Secrets"):
    st.info("""
        ƒê·ªÉ ·ª©ng d·ª•ng c√≥ th·ªÉ t·ª± ƒë·ªông √°nh x·∫° t√™n gi√°o vi√™n v√† l∆∞u d·ªØ li·ªáu l√™n Google Sheets, b·∫°n c·∫ßn:
        1.  **T·∫°o m·ªôt Service Account** tr√™n Google Cloud Platform v√† c·∫•p quy·ªÅn truy c·∫≠p Google Sheets API.
        2.  **Chia s·∫ª file Google Sheet** c·ªßa b·∫°n (ID: `1TJfaywQM1VNGjDbWyC3osTLLOvlgzP0-bQjz8J-_BoI`) v·ªõi ƒë·ªãa ch·ªâ `client_email` c·ªßa Service Account v√† c·∫•p quy·ªÅn **Editor**.
        3.  **Th√™m th√¥ng tin credentials** c·ªßa Service Account v√†o `secrets.toml` c·ªßa ·ª©ng d·ª•ng Streamlit theo m·∫´u d∆∞·ªõi ƒë√¢y.
    """)
    st.code("""
[gcp_service_account]
type = "service_account"
project_id = "your-project-id"
private_key_id = "your-private-key-id"
private_key = "-----BEGIN PRIVATE KEY-----\\n...your-private-key...\\n-----END PRIVATE KEY-----\\n"
client_email = "your-service-account-email@...iam.gserviceaccount.com"
client_id = "your-client-id"
auth_uri = "https://accounts.google.com/o/oauth2/auth"
token_uri = "https://oauth2.googleapis.com/token"
auth_provider_x509_cert_url = "https://www.googleapis.com/oauth2/v1/certs"
client_x509_cert_url = "https://www.googleapis.com/robot/v1/metadata/x509/your-service-account-email..."
    """, language='toml')

# --- K·∫æT N·ªêI V√Ä L·∫§Y D·ªÆ LI·ªÜU √ÅNH X·∫† ---
TEACHER_INFO_SHEET_ID = "1TJfaywQM1VNGjDbWyC3osTLLOvlgzP0-bQjz8J-_BoI"
teacher_mapping_data = {}
gsheet_client = None
if "gcp_service_account" in st.secrets:
    gsheet_client = connect_to_gsheet()
    if gsheet_client:
        teacher_mapping_data = get_teacher_mapping(gsheet_client, TEACHER_INFO_SHEET_ID)
else:
    st.warning("Kh√¥ng t√¨m th·∫•y c·∫•u h√¨nh Google Sheets trong `st.secrets`. C√°c t√≠nh nƒÉng li√™n quan s·∫Ω b·ªã v√¥ hi·ªáu h√≥a.", icon="‚ö†Ô∏è")

uploaded_file = st.file_uploader("Ch·ªçn file Excel c·ªßa b·∫°n", type=["xlsx"])

if uploaded_file is not None:
    try:
        workbook = openpyxl.load_workbook(io.BytesIO(uploaded_file.getvalue()), data_only=True)
        with st.spinner("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu..."):
            raw_df = extract_schedule_from_excel(workbook.active)

        if raw_df is not None:
            db_df = transform_to_database_format(raw_df, teacher_mapping_data)

            # --- PH·∫¶N L∆ØU TR·ªÆ D·ªÆ LI·ªÜU ---
            st.markdown("---")
            st.header("üì§ L∆∞u tr·ªØ d·ªØ li·ªáu")
            st.info(f"D·ªØ li·ªáu sau khi x·ª≠ l√Ω s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o Google Sheet c√≥ ID: **{TEACHER_INFO_SHEET_ID}**")

            col1, col2, col3 = st.columns(3)
            with col1:
                nam_hoc = st.text_input("NƒÉm h·ªçc (VD: 2425):", value="2425")
            with col2:
                hoc_ky = st.text_input("H·ªçc k·ª≥ (VD: HK1):", value="HK1")
            with col3:
                giai_doan = st.text_input("Giai ƒëo·∫°n (VD: GD1):", value="GD1")

            sheet_name = f"DATA_{nam_hoc}_{hoc_ky}_{giai_doan}"
            st.write(f"T√™n sheet s·∫Ω ƒë∆∞·ª£c t·∫°o/c·∫≠p nh·∫≠t l√†: **{sheet_name}**")

            if st.button("L∆∞u d·ªØ li·ªáu l√™n Google Sheet", key="save_button"):
                if gsheet_client:
                    with st.spinner(f"ƒêang l∆∞u d·ªØ li·ªáu v√†o sheet '{sheet_name}'..."):
                        db_df_str = db_df.astype(str)
                        success, error_message = save_df_to_gsheet(gsheet_client, TEACHER_INFO_SHEET_ID, sheet_name, db_df_str)
                        if success:
                            st.success(f"L∆∞u d·ªØ li·ªáu th√†nh c√¥ng! Vui l√≤ng ki·ªÉm tra Google Sheet.")
                        else:
                            st.error(f"L·ªói khi l∆∞u d·ªØ li·ªáu: {error_message}")
                else:
                    st.error("Kh√¥ng th·ªÉ l∆∞u do ch∆∞a k·∫øt n·ªëi ƒë∆∞·ª£c v·ªõi Google Sheets. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh secrets.")

            # --- PH·∫¶N TRA C·ª®U V√Ä HI·ªÇN TH·ªä ---
            st.markdown("---")
            st.header("üîç Tra c·ª©u Th·ªùi Kh√≥a Bi·ªÉu")
            
            class_list = sorted(db_df['L·ªõp'].unique())
            selected_class = st.selectbox("Ch·ªçn l·ªõp ƒë·ªÉ xem chi ti·∫øt:", options=class_list)

            if selected_class:
                class_schedule = db_df[db_df['L·ªõp'] == selected_class].copy()
                
                st.markdown("##### üìù Th√¥ng tin chung c·ªßa l·ªõp")
                info = class_schedule.iloc[0]
                info_cols = st.columns(4)
                with info_cols[0]:
                    st.metric(label="GV Ch·ªß nhi·ªám", value=info.get("Gi√°o vi√™n CN") or "Ch∆∞a c√≥")
                with info_cols[1]:
                    st.metric(label="Tr√¨nh ƒë·ªô", value=info.get("Tr√¨nh ƒë·ªô") or "Ch∆∞a c√≥")
                with info_cols[2]:
                    st.metric(label="Sƒ© s·ªë", value=str(info.get("Sƒ© s·ªë") or "N/A"))
                with info_cols[3]:
                    st.metric(label="Ph√≤ng SHCN", value=info.get("Ph√≤ng SHCN") or "Ch∆∞a c√≥")

                st.markdown("--- \n ##### üóìÔ∏è L·ªãch h·ªçc chi ti·∫øt")

                number_to_day_map = {2: 'TH·ª® HAI', 3: 'TH·ª® BA', 4: 'TH·ª® T∆Ø', 5: 'TH·ª® NƒÇM', 6: 'TH·ª® S√ÅU', 7: 'TH·ª® B·∫¢Y'}
                class_schedule['Th·ª© ƒê·∫ßy ƒê·ªß'] = class_schedule['Th·ª©'].map(number_to_day_map)
                
                day_order = list(number_to_day_map.values())
                session_order = ['S√°ng', 'Chi·ªÅu']
                class_schedule['Th·ª© ƒê·∫ßy ƒê·ªß'] = pd.Categorical(class_schedule['Th·ª© ƒê·∫ßy ƒê·ªß'], categories=day_order, ordered=True)
                class_schedule['Bu·ªïi'] = pd.Categorical(class_schedule['Bu·ªïi'], categories=session_order, ordered=True)
                
                class_schedule_sorted = class_schedule.sort_values(by=['Th·ª© ƒê·∫ßy ƒê·ªß', 'Bu·ªïi', 'Ti·∫øt'])

                for day, day_group in class_schedule_sorted.groupby('Th·ª© ƒê·∫ßy ƒê·ªß', observed=False):
                    with st.expander(f"**{day}**"):
                        
                        can_consolidate = False
                        sessions = day_group['Bu·ªïi'].unique()
                        if set(sessions) == {'S√°ng', 'Chi·ªÅu'}:
                            sang_group = day_group[day_group['Bu·ªïi'] == 'S√°ng']
                            chieu_group = day_group[day_group['Bu·ªïi'] == 'Chi·ªÅu']
                            
                            sang_subjects = sang_group[['M√¥n h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng h·ªçc']].drop_duplicates()
                            chieu_subjects = chieu_group[['M√¥n h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng h·ªçc']].drop_duplicates()
                            
                            if len(sang_subjects) == 1 and sang_subjects.equals(chieu_subjects):
                                can_consolidate = True

                        blue_color = "#60A5FA"
                        green_color = "#00FF00"

                        if can_consolidate:
                            subject_info = sang_subjects.iloc[0]
                            all_periods = day_group['Ti·∫øt'].astype(str).tolist()
                            tiet_str = ", ".join(sorted(all_periods, key=int))
                            
                            session_header = f"<span style='color:{blue_color}; font-weight:bold;'>C·∫£ ng√†y:</span>"
                            
                            subject_part = f"üìñ **M√¥n:** <span style='color:{green_color};'>{subject_info['M√¥n h·ªçc']}</span>"
                            tiet_part = f"‚è∞ **Ti·∫øt:** <span style='color:{green_color};'>{tiet_str}</span>"
                            gv_part = f"üßë‚Äçüíº **GV:** <span style='color:{green_color};'>{subject_info['Gi√°o vi√™n BM']}</span>" if subject_info['Gi√°o vi√™n BM'] else ""
                            phong_part = f"üè§ **Ph√≤ng:** <span style='color:{green_color};'>{subject_info['Ph√≤ng h·ªçc']}</span>" if subject_info['Ph√≤ng h·ªçc'] else ""

                            all_parts = [part for part in [subject_part, tiet_part, gv_part, phong_part] if part]
                            details_str = "&nbsp;&nbsp;".join(all_parts)
                            full_line = f"{session_header}&nbsp;&nbsp;{details_str}"
                            st.markdown(full_line, unsafe_allow_html=True)
                        
                        else:
                            day_summary_parts = []
                            for session, session_group in day_group.groupby('Bu·ªïi', observed=False):
                                session_header = f"<span style='color:{blue_color}; font-weight:bold;'>Bu·ªïi {session.lower()}:</span>"
                                
                                subjects_in_session = {}
                                for _, row in session_group.iterrows():
                                    subject = row['M√¥n h·ªçc']
                                    if pd.notna(subject) and subject.strip():
                                        key = (subject, row['Gi√°o vi√™n BM'], row['Ph√≤ng h·ªçc'])
                                        if key not in subjects_in_session: subjects_in_session[key] = []
                                        subjects_in_session[key].append(str(row['Ti·∫øt']))

                                if not subjects_in_session:
                                    day_summary_parts.append(f"{session_header}&nbsp;&nbsp;‚ú®Ngh·ªâ")
                                else:
                                    for (subject, gv, phong), tiet_list in subjects_in_session.items():
                                        tiet_str = ", ".join(sorted(tiet_list, key=int))
                                        
                                        subject_part = f"üìñ **M√¥n:** <span style='color:{green_color};'>{subject}</span>"
                                        tiet_part = f"‚è∞ **Ti·∫øt:** <span style='color:{green_color};'>{tiet_str}</span>"
                                        gv_part = f"üßë‚Äçüíº **GV:** <span style='color:{green_color};'>{gv}</span>" if gv else ""
                                        phong_part = f"üè§ **Ph√≤ng:** <span style='color:{green_color};'>{phong}</span>" if phong else ""

                                        all_parts = [part for part in [subject_part, tiet_part, gv_part, phong_part] if part]
                                        details_str = "&nbsp;&nbsp;".join(all_parts)
                                        
                                        full_line = f"{session_header}&nbsp;&nbsp;{details_str}"
                                        day_summary_parts.append(full_line)
                            
                            st.markdown("<br>".join(day_summary_parts), unsafe_allow_html=True)

                with st.expander("Xem b·∫£ng d·ªØ li·ªáu chi ti·∫øt c·ªßa l·ªõp"):
                    display_columns = ['Th·ª©', 'Bu·ªïi', 'Ti·∫øt', 'M√¥n h·ªçc', 'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 'Ghi ch√∫']
                    st.dataframe(
                        class_schedule_sorted[display_columns].rename(columns={'Th·ª© ƒê·∫ßy ƒê·ªß': 'Th·ª©'}),
                        use_container_width=True,
                        hide_index=True
                    )
        else:
            st.warning("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë·ªãnh d·∫°ng file c·ªßa b·∫°n.")

    except Exception as e:
        st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω file: {e}")
