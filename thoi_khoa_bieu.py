# thoi_khoa_bieu.py

import streamlit as st
import pandas as pd
import openpyxl
import io
import re
import gspread
from google.oauth2.service_account import Credentials
from unidecode import unidecode

# --- C√ÅC H√ÄM K·∫æT N·ªêI V√Ä T·∫¢I D·ªÆ LI·ªÜU T·ª™ GOOGLE SHEETS ---

@st.cache_resource
def connect_to_gsheet():
    """K·∫øt n·ªëi t·ªõi Google Sheets s·ª≠ d·ª•ng service account credentials."""
    try:
        creds_dict = st.secrets["gcp_service_account"]
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive.file"
        ]
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi Google Sheets: {e}")
        return None

@st.cache_data(ttl=600)
def load_abbreviations_map(_gsheet_client, spreadsheet_id):
    """T·∫£i b·∫£n ƒë·ªì √°nh x·∫° vi·∫øt t·∫Øt t·ª´ sheet VIET_TAT ƒë·ªÉ d√πng cho B∆∞·ªõc 2."""
    if _gsheet_client is None: return {}
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("VIET_TAT")
        records = worksheet.get_all_records()
        abbreviations_map = {
            str(record.get('Vi·∫øt_t·∫Øt_1')).strip().lower(): str(record.get('ƒê·∫ßy_ƒë·ªß_1')).strip()
            for record in records if record.get('Vi·∫øt_t·∫Øt_1') and record.get('ƒê·∫ßy_ƒë·ªß_1')
        }
        return abbreviations_map
    except gspread.exceptions.WorksheetNotFound:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet 'VIET_TAT'.")
        return {}
    except Exception as e:
        st.warning(f"‚ö†Ô∏è L·ªói khi t·∫£i danh s√°ch vi·∫øt t·∫Øt t·ª´ sheet 'VIET_TAT': {e}")
        return {}

@st.cache_data(ttl=600)
def load_common_subjects_map(_gsheet_client, spreadsheet_id):
    """T·∫£i b·∫£n ƒë·ªì √°nh x·∫° T√™n m√¥n chung v√† M√£ m√¥n chung t·ª´ sheet DANH_MUC ƒë·ªÉ d√πng cho B∆∞·ªõc 3."""
    if _gsheet_client is None: return {}
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("DANH_MUC")
        records = worksheet.get_all_records()
        common_map = {
            str(rec.get('T√™n_m√¥nchung')).strip(): str(rec.get('M√£_m√¥nchung')).strip()
            for rec in records if rec.get('T√™n_m√¥nchung') and rec.get('M√£_m√¥nchung')
        }
        return common_map
    except gspread.exceptions.WorksheetNotFound:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet 'DANH_MUC'.")
        return {}
    except Exception as e:
        st.warning(f"‚ö†Ô∏è L·ªói khi t·∫£i danh s√°ch m√¥n chung t·ª´ sheet 'DANH_MUC': {e}")
        return {}

@st.cache_data(ttl=600)
def load_teacher_info(_gsheet_client, spreadsheet_id):
    """T·∫£i d·ªØ li·ªáu gi√°o vi√™n t·ª´ sheet THONG_TIN_GV."""
    if _gsheet_client is None: return pd.DataFrame()
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("THONG_TIN_GV")
        df = pd.DataFrame(worksheet.get_all_records())
        return df
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu gi√°o vi√™n: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=60)
def get_khoa_list(_gsheet_client, spreadsheet_id):
    """T·∫£i danh s√°ch Khoa t·ª´ sheet DANH_MUC."""
    if _gsheet_client is None: return []
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("DANH_MUC")
        df = pd.DataFrame(worksheet.get_all_records())
        return df["Khoa/Ph√≤ng/Trung t√¢m"].dropna().unique().tolist()
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i danh s√°ch khoa: {e}")
        return []

# --- C√ÅC H√ÄM LOGIC X·ª¨ L√ù D·ªÆ LI·ªÜU (THEO QUY TR√åNH M·ªöI) ---

def expand_subject_abbreviations(df, abbreviations_map):
    """(B∆∞·ªõc 2) Duy·ªát c·ªôt 'M√¥n h·ªçc' v√† d·ªãch c√°c t·ª´ vi·∫øt t·∫Øt sang t√™n ƒë·∫ßy ƒë·ªß."""
    if 'M√¥n h·ªçc' in df.columns and abbreviations_map:
        df['M√¥n h·ªçc'] = df['M√¥n h·ªçc'].apply(
            lambda x: abbreviations_map.get(str(x).strip().lower(), str(x).strip())
        )
    return df

def assign_common_subject_codes(df, common_subjects_map):
    """(B∆∞·ªõc 3) So s√°nh t√™n m√¥n h·ªçc ƒë·∫ßy ƒë·ªß v·ªõi danh s√°ch m√¥n chung v√† g√°n m√£ m√¥n."""
    if 'M√¥n h·ªçc' in df.columns and 'M√£ m√¥n' in df.columns and common_subjects_map:
        df['M√£ m√¥n'] = df['M√¥n h·ªçc'].map(common_subjects_map).fillna('')
    return df

def create_teacher_mapping(df_schedule, df_teacher_info_full, selected_khoa):
    """T·∫°o b·∫£n ƒë·ªì √°nh x·∫° t√™n GV ƒë·ªÉ chu·∫©n b·ªã cho vi·ªác thay th·∫ø."""
    df_teacher_info_full['First_name_normalized'] = df_teacher_info_full['Ho_ten_gv'].astype(str).apply(lambda x: unidecode(x.split(' ')[-1]).lower())
    
    def get_all_individual_names(series):
        names = set()
        for item in series.dropna():
            for name in str(item).split(' / '):
                if name.strip(): names.add(name.strip())
        return names

    all_short_names = get_all_individual_names(df_schedule['Gi√°o vi√™n BM']).union(get_all_individual_names(df_schedule['Gi√°o vi√™n CN']))
    
    df_teachers_in_khoa = df_teacher_info_full[df_teacher_info_full['Khoa'] == selected_khoa].copy()
    mapping = {}

    if 'Ten_viet_tat' in df_teachers_in_khoa.columns:
        df_with_shortnames = df_teachers_in_khoa.dropna(subset=['Ten_viet_tat'])
        for _, row in df_with_shortnames.iterrows():
            for short_name in str(row['Ten_viet_tat']).split(';'):
                sn_clean = short_name.strip()
                if sn_clean: mapping[sn_clean] = {'full_name': row['Ho_ten_gv'], 'id': row['Ma_gv']}

    for short_name in all_short_names:
        if short_name in mapping: continue
        match = re.match(r'([TC])\.(.*)', short_name)
        if not match:
            mapping[short_name] = {'full_name': short_name, 'id': ''}
            continue

        prefix, name_part = match.groups()
        name_part_normalized = unidecode(name_part.strip()).lower()
        possible_matches = df_teachers_in_khoa[df_teachers_in_khoa['First_name_normalized'] == name_part_normalized]

        if len(possible_matches) == 1:
            matched_teacher = possible_matches.iloc[0]
            mapping[short_name] = {'full_name': matched_teacher['Ho_ten_gv'], 'id': matched_teacher['Ma_gv']}
        else:
            mapping[short_name] = {'full_name': short_name, 'id': ''}
    return mapping

# --- H√ÄM X·ª¨ L√ù EXCEL V√Ä CHUY·ªÇN ƒê·ªîI ---

def extract_schedule_from_excel(worksheet):
    """Tr√≠ch xu·∫•t d·ªØ li·ªáu th√¥ t·ª´ m·ªôt sheet Excel."""
    ngay_ap_dung = ""
    for r_idx in range(1, 6):
        for c_idx in range(1, 27):
            cell_value = str(worksheet.cell(row=r_idx, column=c_idx).value or '').strip()
            if "√°p d·ª•ng" in cell_value.lower():
                date_match = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', cell_value)
                if date_match:
                    ngay_ap_dung = date_match.group(1)
                    break
        if ngay_ap_dung: break

    start_row, start_col = -1, -1
    for r_idx, row in enumerate(worksheet.iter_rows(min_row=1, max_row=10), 1):
        for c_idx, cell in enumerate(row, 1):
            if cell.value and "th·ª©" in str(cell.value).lower():
                start_row, start_col = r_idx, c_idx
                break
        if start_row != -1: break
    if start_row == -1: return None, None

    data = []
    for row in worksheet.iter_rows(min_row=start_row):
        data.append([cell.value for cell in row])
    
    if not data: return None, ngay_ap_dung

    header_level1, header_level2 = data[0], data[1]
    filled_header_level1 = []
    last_val = ""
    for val in header_level1:
        if val is not None and str(val).strip() != '': last_val = val
        filled_header_level1.append(last_val)

    combined_headers = [f"{str(h1 or '').strip()}___{str(h2 or '').strip()}" if i >= 3 else str(h1 or '').strip() for i, (h1, h2) in enumerate(zip(filled_header_level1, header_level2))]
    df = pd.DataFrame(data[2:], columns=combined_headers)
    df = df.dropna(how='all')
    return df, ngay_ap_dung

def transform_to_database_format(df_wide, ngay_ap_dung):
    """(B∆∞·ªõc 1) B√≥c t√°ch d·ªØ li·ªáu t·ª´ ƒë·ªãnh d·∫°ng ngang sang ƒë·ªãnh d·∫°ng d·ªçc."""
    id_vars = ['Th·ª©', 'Bu·ªïi', 'Ti·∫øt']
    df_long = pd.melt(df_wide, id_vars=id_vars, var_name='L·ªõp_Raw', value_name='Chi ti·∫øt M√¥n h·ªçc')
    df_long.dropna(subset=['Chi ti·∫øt M√¥n h·ªçc'], inplace=True)
    df_long = df_long[df_long['Chi ti·∫øt M√¥n h·ªçc'].astype(str).str.strip() != '']

    def parse_subject_details_custom(cell_text):
        clean_text = re.sub(r'\s{2,}', ' ', str(cell_text).replace('\n', ' ').strip())
        ghi_chu, remaining_text = "", clean_text
        
        note_match = re.search(r'(\((?:H·ªçc t·ª´|Ch·ªâ h·ªçc).*?\))$', clean_text, re.IGNORECASE)
        if note_match:
            ghi_chu = note_match.group(1).strip('()').strip()
            remaining_text = clean_text.replace(note_match.group(0), '').strip()
            
        if "THPT" in remaining_text.upper():
            return ("H·ªåC TKB VƒÇN H√ìA THPT", "", "", ghi_chu)

        match = re.search(r'^(.*?)\s*\((.*)\)$', remaining_text)
        if match:
            mon_hoc = match.group(1).strip()
            content_in_parens = match.group(2).strip()
            if '-' in content_in_parens:
                parts = content_in_parens.split('-', 1)
                phong_hoc, gv_part = parts[0].strip(), parts[1].strip()
            else:
                phong_hoc, gv_part = "", content_in_parens
            gv = " / ".join([g.strip() for g in gv_part.split('/')])
            return (mon_hoc, phong_hoc, gv, ghi_chu)
        else:
            return (remaining_text, "", "", ghi_chu)

    parsed_cols = df_long['Chi ti·∫øt M√¥n h·ªçc'].apply(parse_subject_details_custom)
    mh_extracted = pd.DataFrame(parsed_cols.tolist(), index=df_long.index, columns=['M√¥n h·ªçc', 'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 'Ghi ch√∫'])
    
    header_parts = df_long['L·ªõp_Raw'].str.split('___', expand=True)
    lop_extracted = header_parts[0].str.extract(r'^(.*?)\s*(?:\((\d+)\))?$')
    lop_extracted.columns = ['L·ªõp', 'Sƒ© s·ªë']

    def parse_cn_details(text):
        if not text or pd.isna(text): return ("", "", "")
        text = str(text).strip('()')
        parts = text.split('-')
        return (parts[0].strip(), parts[1].strip() if len(parts) > 1 else "", "")

    cn_details = header_parts[1].apply(parse_cn_details) if len(header_parts.columns) > 1 else pd.Series([("", "", "")] * len(df_long))
    cn_extracted = pd.DataFrame(cn_details.tolist(), index=df_long.index, columns=['Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 'L·ªõp VHPT'])
    
    df_final = pd.concat([df_long[['Th·ª©', 'Bu·ªïi', 'Ti·∫øt']].reset_index(drop=True), lop_extracted.reset_index(drop=True), cn_extracted.reset_index(drop=True), mh_extracted.reset_index(drop=True)], axis=1)
    df_final['Tr√¨nh ƒë·ªô'] = df_final['L·ªõp'].apply(lambda x: 'Cao ƒë·∫≥ng' if 'C.' in str(x) else ('Trung C·∫•p' if 'T.' in str(x) else ''))
    
    df_final['M√£ m√¥n'] = ''
    df_final['Ma_gv_bm'] = ''
    df_final['Ma_gv_cn'] = ''
    df_final['KHOA'] = ''
    df_final['Ng√†y √°p d·ª•ng'] = ngay_ap_dung
    df_final.fillna('', inplace=True)
    
    final_cols = ['Th·ª©', 'Bu·ªïi', 'Ti·∫øt', 'L·ªõp', 'Sƒ© s·ªë', 'Tr√¨nh ƒë·ªô', 'M√¥n h·ªçc', 'M√£ m√¥n', 
                  'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 'Ma_gv_bm', 'Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 
                  'Ma_gv_cn', 'L·ªõp VHPT', 'Ghi ch√∫', 'KHOA', 'Ng√†y √°p d·ª•ng']
    return df_final[final_cols]

# --- Giao di·ªán ch√≠nh c·ªßa ·ª©ng d·ª•ng Streamlit ---

st.set_page_config(page_title="Qu·∫£n l√Ω TKB", layout="wide")
st.title("üì• T·∫£i l√™n & X·ª≠ l√Ω Th·ªùi Kh√≥a Bi·ªÉu")

# --- T·∫£i d·ªØ li·ªáu ban ƒë·∫ßu ---
TEACHER_INFO_SHEET_ID = st.secrets.get("google_sheet", {}).get("teacher_info_sheet_id", "1TJfaywQM1VNGjDbWyC3osTLLOvlgzP0-bQjz8J-_BoI")
gsheet_client = connect_to_gsheet()

abbreviations_map = {}
common_subjects_map = {}
df_teacher_info = pd.DataFrame()

if gsheet_client:
    abbreviations_map = load_abbreviations_map(gsheet_client, TEACHER_INFO_SHEET_ID)
    common_subjects_map = load_common_subjects_map(gsheet_client, TEACHER_INFO_SHEET_ID)
    df_teacher_info = load_teacher_info(gsheet_client, TEACHER_INFO_SHEET_ID)

# --- Giao di·ªán t·∫£i file v√† x·ª≠ l√Ω ---
uploaded_file = st.file_uploader("Ch·ªçn file Excel TKB c·ªßa b·∫°n", type=["xlsx"])

if uploaded_file:
    workbook = openpyxl.load_workbook(io.BytesIO(uploaded_file.getvalue()), data_only=True)
    all_sheet_names = workbook.sheetnames
    sheets_to_display = [s for s in all_sheet_names if s.upper() not in ["DANH_MUC", "THONG_TIN_GV", "VIET_TAT"]]
    selected_sheets = st.multiselect("Ch·ªçn c√°c sheet TKB c·∫ßn x·ª≠ l√Ω:", options=sheets_to_display)

    if st.button("X·ª≠ l√Ω c√°c sheet ƒë√£ ch·ªçn"):
        all_processed_dfs = []
        with st.spinner("B∆∞·ªõc 1: ƒêang ƒë·ªçc v√† b√≥c t√°ch d·ªØ li·ªáu t·ª´ file Excel..."):
            for sheet_name in selected_sheets:
                worksheet = workbook[sheet_name]
                raw_df, ngay_ap_dung = extract_schedule_from_excel(worksheet)
                if raw_df is not None and not raw_df.empty:
                    db_df = transform_to_database_format(raw_df, ngay_ap_dung)
                    all_processed_dfs.append(db_df)

        if all_processed_dfs:
            combined_df = pd.concat(all_processed_dfs, ignore_index=True)
            
            with st.spinner("B∆∞·ªõc 2: ƒêang d·ªãch t√™n m√¥n h·ªçc vi·∫øt t·∫Øt..."):
                df_expanded = expand_subject_abbreviations(combined_df, abbreviations_map)
            
            with st.spinner("B∆∞·ªõc 3: ƒêang g√°n m√£ cho c√°c m√¥n h·ªçc chung..."):
                df_finalized = assign_common_subject_codes(df_expanded, common_subjects_map)
            
            st.session_state['processed_df'] = df_finalized
            st.success("X·ª≠ l√Ω th√†nh c√¥ng! D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng ƒë·ªÉ √°nh x·∫° v√† l∆∞u.")
        else:
            st.warning("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c sheet ƒë√£ ch·ªçn.")

    if 'processed_df' in st.session_state:
        db_df_to_process = st.session_state['processed_df']
        st.markdown("---")
        st.subheader("üì§ L∆∞u tr·ªØ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1: nam_hoc = st.text_input("NƒÉm h·ªçc:", value="2425")
        with col2: hoc_ky = st.text_input("H·ªçc k·ª≥:", value="HK1")
        with col3: giai_doan = st.text_input("Giai ƒëo·∫°n:", value="GD1")
        with col4:
            khoa_list = get_khoa_list(gsheet_client, TEACHER_INFO_SHEET_ID)
            khoa = st.selectbox("Ch·ªçn Khoa ƒë·ªÉ g√°n cho d·ªØ li·ªáu:", options=khoa_list)

        if st.button("√Ånh x·∫° gi√°o vi√™n v√† L∆∞u v√†o Google Sheet"):
            with st.spinner("ƒêang √°nh x·∫° gi√°o vi√™n v√† chu·∫©n b·ªã d·ªØ li·ªáu..."):
                df_to_save = db_df_to_process.copy()
                df_to_save['KHOA'] = khoa
                
                teacher_mapping = create_teacher_mapping(df_to_save, df_teacher_info, khoa)
                
                def apply_mapping(name_str, key):
                    if pd.isna(name_str) or not str(name_str).strip(): return ""
                    names_list = [n.strip() for n in str(name_str).split(' / ')]
                    mapped_names = [str(teacher_mapping.get(name, {}).get(key, name)) for name in names_list]
                    return " / ".join(mapped_names)

                df_to_save['Ma_gv_bm'] = df_to_save['Gi√°o vi√™n BM'].apply(apply_mapping, key='id')
                df_to_save['Gi√°o vi√™n BM'] = df_to_save['Gi√°o vi√™n BM'].apply(apply_mapping, key='full_name')
                df_to_save['Ma_gv_cn'] = df_to_save['Gi√°o vi√™n CN'].apply(apply_mapping, key='id')
                df_to_save['Gi√°o vi√™n CN'] = df_to_save['Gi√°o vi√™n CN'].apply(apply_mapping, key='full_name')

            with st.spinner("ƒêang l∆∞u d·ªØ li·ªáu v√†o Google Sheet..."):
                sheet_name = f"DATA_{nam_hoc}_{hoc_ky}_{giai_doan}"
                # (H√†m update_gsheet_by_khoa v√† bulk_update_teacher_info c·∫ßn ƒë∆∞·ª£c g·ªçi ·ªü ƒë√¢y n·∫øu c√≥)
                # T·∫°m th·ªùi ch·ªâ l∆∞u d·ªØ li·ªáu ch√≠nh
                st.success(f"D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng ƒë·ªÉ l∆∞u v√†o sheet '{sheet_name}'.")
                # success, msg = update_gsheet_by_khoa(gsheet_client, TEACHER_INFO_SHEET_ID, sheet_name, df_to_save, khoa)
                # if success:
                #     st.success(f"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng v√†o sheet '{sheet_name}'!")
                #     st.cache_data.clear()
                # else:
                #     st.error(f"L·ªói khi l∆∞u d·ªØ li·ªáu: {msg}")

        with st.expander("Xem tr∆∞·ªõc d·ªØ li·ªáu cu·ªëi c√πng (s·∫µn s√†ng ƒë·ªÉ l∆∞u)"):
            st.dataframe(db_df_to_process)
