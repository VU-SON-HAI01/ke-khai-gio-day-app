# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
import streamlit as st
import pandas as pd
import openpyxl
import io
import re
import gspread
from google.oauth2.service_account import Credentials

# --- CÃC HÃ€M Káº¾T Ná»I GOOGLE SHEETS ---

@st.cache_resource
def connect_to_gsheet():
    """
    Káº¿t ná»‘i tá»›i Google Sheets sá»­ dá»¥ng Service Account credentials tá»« st.secrets.
    """
    try:
        creds_dict = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"Lá»—i káº¿t ná»‘i Google Sheets: {e}")
        return None

@st.cache_data(ttl=600)
def get_teacher_mapping(_gsheet_client, spreadsheet_id):
    """
    Láº¥y dá»¯ liá»‡u Ã¡nh xáº¡ tÃªn giÃ¡o viÃªn tá»« Google Sheet.
    """
    if _gsheet_client is None: return {}
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("THONG_TIN_GV")
        df = pd.DataFrame(worksheet.get_all_records())
        required_cols = ["Ten_viet_tat", "Ho_ten_gv"]
        if not all(col in df.columns for col in required_cols):
            st.error("Lá»—i: Sheet 'THONG_TIN_GV' bá»‹ thiáº¿u cá»™t báº¯t buá»™c.")
            return {}
        return pd.Series(df.Ho_ten_gv.values, index=df.Ten_viet_tat.str.strip()).to_dict()
    except Exception as e:
        st.error(f"Lá»—i khi táº£i dá»¯ liá»‡u giÃ¡o viÃªn: {e}")
        return {}

@st.cache_data(ttl=60)
def get_khoa_list(_gsheet_client, spreadsheet_id):
    """
    Láº¥y danh sÃ¡ch Khoa/PhÃ²ng/Trung tÃ¢m tá»« sheet DANH_MUC.
    """
    if _gsheet_client is None: return []
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("DANH_MUC")
        df = pd.DataFrame(worksheet.get_all_records())
        khoa_col = "Khoa/PhÃ²ng/Trung tÃ¢m"
        if khoa_col in df.columns:
            return df[khoa_col].dropna().unique().tolist()
        else:
            st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y cá»™t '{khoa_col}' trong sheet 'DANH_MUC'.")
            return []
    except gspread.exceptions.WorksheetNotFound:
        st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y sheet 'DANH_MUC'. Vui lÃ²ng táº¡o sheet nÃ y.")
        return []
    except Exception as e:
        st.error(f"Lá»—i khi táº£i danh sÃ¡ch khoa: {e}")
        return []

def update_gsheet_by_khoa(client, spreadsheet_id, sheet_name, df_new, khoa_to_update):
    """
    Cáº­p nháº­t dá»¯ liá»‡u trong sheet dá»±a trÃªn Khoa.
    """
    try:
        spreadsheet = client.open_by_key(spreadsheet_id)
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
            existing_data = worksheet.get_all_records()
            if existing_data:
                df_existing = pd.DataFrame(existing_data)
                df_others = df_existing[df_existing['KHOA'] != khoa_to_update]
                df_combined = pd.concat([df_others, df_new], ignore_index=True)
            else: 
                df_combined = df_new
        except gspread.WorksheetNotFound:
            df_combined = df_new
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows="1", cols="1")

        worksheet.clear()
        data_to_upload = [df_combined.columns.values.tolist()] + df_combined.astype(str).values.tolist()
        worksheet.update(data_to_upload, 'A1')
        return True, None
    except Exception as e:
        return False, str(e)

@st.cache_data(ttl=60)
def get_all_data_sheets(_client, spreadsheet_id):
    if not _client: return []
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        return [s.title for s in spreadsheet.worksheets() if s.title.startswith("DATA_")]
    except Exception as e:
        st.error(f"Lá»—i khi láº¥y danh sÃ¡ch sheet: {e}"); return []

@st.cache_data(ttl=60)
def load_data_from_gsheet(_client, spreadsheet_id, sheet_name):
    if not _client or not sheet_name: return pd.DataFrame()
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet(sheet_name)
        df = pd.DataFrame(worksheet.get_all_records())
        for col in ['Thá»©', 'Tiáº¿t']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        return df
    except Exception as e:
        st.error(f"Lá»—i khi táº£i dá»¯ liá»‡u tá»« sheet '{sheet_name}': {e}"); return pd.DataFrame()

# --- CÃC HÃ€M Xá»¬ LÃ EXCEL ---

def extract_schedule_from_excel(worksheet):
    ngay_ap_dung = ""
    for r_idx in range(1, 6):
        for c_idx in range(1, 10):
            cell_value = str(worksheet.cell(row=r_idx, column=c_idx).value or '').strip()
            if "Ã¡p dá»¥ng" in cell_value.lower():
                # TÃ¬m kiáº¿m ngÃ y thÃ¡ng linh hoáº¡t hÆ¡n
                date_match = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', cell_value)
                if date_match:
                    ngay_ap_dung = date_match.group(1)
                else:
                    try:
                        next_cell_value = str(worksheet.cell(row=r_idx, column=c_idx + 1).value or '')
                        date_match_next = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', next_cell_value)
                        if date_match_next:
                            ngay_ap_dung = date_match_next.group(1)
                    except:
                        pass
                break
        if ngay_ap_dung: break

    start_row, start_col = -1, -1
    for r_idx, row in enumerate(worksheet.iter_rows(min_row=1, max_row=10), 1):
        for c_idx, cell in enumerate(row, 1):
            if cell.value and "thá»©" in str(cell.value).lower():
                start_row, start_col = r_idx, c_idx; break
        if start_row != -1: break
    if start_row == -1:
        st.error("KhÃ´ng tÃ¬m tháº¥y Ã´ tiÃªu Ä‘á» 'Thá»©' trong 10 dÃ²ng Ä‘áº§u tiÃªn."); return None, None
    
    last_row = start_row
    for r_idx in range(worksheet.max_row, start_row - 1, -1):
        cell_value = worksheet.cell(row=r_idx, column=start_col + 2).value
        if cell_value is not None and isinstance(cell_value, (int, float)):
            last_row = r_idx; break
    last_col = start_col
    for row in worksheet.iter_rows(min_row=start_row, max_row=last_row):
        for cell in row:
            if cell.value is not None and cell.column > last_col: last_col = cell.column
    
    merged_values = {}
    for merged_range in worksheet.merged_cells.ranges:
        top_left_cell = worksheet.cell(row=merged_range.min_row, column=merged_range.min_col)
        for row_ in range(merged_range.min_row, merged_range.max_row + 1):
            for col_ in range(merged_range.min_col, merged_range.max_col + 1):
                merged_values[(row_, col_)] = top_left_cell.value
    
    day_to_number_map = {'HAI': 2, 'BA': 3, 'TÆ¯': 4, 'NÄ‚M': 5, 'SÃU': 6, 'Báº¢Y': 7}
    data = []
    for r_idx in range(start_row, last_row + 1):
        row_data = [merged_values.get((r_idx, c_idx), worksheet.cell(row=r_idx, column=c_idx).value) for c_idx in range(start_col, last_col + 1)]
        if r_idx > start_row:
            clean_day = re.sub(r'\s+', '', str(row_data[0] or '')).strip().upper()
            row_data[0] = day_to_number_map.get(clean_day, row_data[0])
        data.append(row_data)
    
    if not data: return None, ngay_ap_dung
    
    header_level1, header_level2 = data[0], data[1]
    filled_header_level1 = []
    last_val = ""
    for val in header_level1:
        if val is not None and str(val).strip() != '': last_val = val
        filled_header_level1.append(last_val)
    
    combined_headers = [f"{str(h1 or '').strip()}___{str(h2 or '').strip()}" if i >= 3 else str(h1 or '').strip() for i, (h1, h2) in enumerate(zip(filled_header_level1, header_level2))]
    df = pd.DataFrame(data[2:], columns=combined_headers)
    return df, ngay_ap_dung

def map_and_prefix_teacher_name(short_name, mapping):
    short_name_clean = str(short_name or '').strip()
    if not short_name_clean: return ''
    full_name = mapping.get(short_name_clean)
    if full_name:
        if short_name_clean.startswith('T.'): return f"Tháº§y {full_name}"
        if short_name_clean.startswith('C.'): return f"CÃ´ {full_name}"
        return full_name
    return short_name_clean

def transform_to_database_format(df_wide, teacher_mapping, ngay_ap_dung):
    id_vars = ['Thá»©', 'Buá»•i', 'Tiáº¿t']
    df_long = pd.melt(df_wide, id_vars=id_vars, var_name='Lá»›p_Raw', value_name='Chi tiáº¿t MÃ´n há»c')
    df_long.dropna(subset=['Chi tiáº¿t MÃ´n há»c'], inplace=True)
    df_long = df_long[df_long['Chi tiáº¿t MÃ´n há»c'].astype(str).str.strip() != '']
    
    def parse_subject_details_custom(cell_text):
        clean_text = re.sub(r'\s{2,}', ' ', str(cell_text).replace('\n', ' ').strip())
        ghi_chu = ""
        note_match = re.search(r'\(?(Há»c tá»«.*?)\)?', clean_text, re.IGNORECASE)
        if note_match:
            ghi_chu = note_match.group(1).strip()
            clean_text = clean_text.replace(note_match.group(0), '').strip()
        remaining_text = clean_text
        if "THPT" in remaining_text.upper():
            return ("Há»ŒC TKB VÄ‚N HÃ“A THPT", "", "", ghi_chu)
        match = re.search(r'^(.*?)\s*\((.*?)\s*-\s*(.*?)\)$', remaining_text)
        if match:
            mon_hoc, phong_hoc, giao_vien = match.group(1).strip(), match.group(2).strip(), match.group(3).strip()
            after_paren_text = remaining_text[match.end():].strip()
            if after_paren_text: ghi_chu = f"{ghi_chu} {after_paren_text}".strip()
            return (mon_hoc, phong_hoc, giao_vien, ghi_chu)
        return (remaining_text, "", "", ghi_chu)

    parsed_cols = df_long['Chi tiáº¿t MÃ´n há»c'].apply(parse_subject_details_custom)
    mh_extracted = pd.DataFrame(parsed_cols.tolist(), index=df_long.index, columns=['MÃ´n há»c', 'PhÃ²ng há»c', 'GiÃ¡o viÃªn BM', 'Ghi chÃº'])
    
    header_parts = df_long['Lá»›p_Raw'].str.split('___', expand=True)
    lop_extracted = header_parts[0].str.extract(r'^(.*?)\s*(?:\((\d+)\))?$'); lop_extracted.columns = ['Lá»›p', 'SÄ© sá»‘']
    
    def parse_cn_details(text):
        if not text or pd.isna(text): return ("", "", "")
        text = str(text).replace('(', '').replace(')', '')
        parts = text.split('-')
        phong_shcn = parts[0].strip()
        gvcn = parts[1].strip() if len(parts) > 1 else ""
        return (phong_shcn, gvcn, "")

    cn_details = header_parts[1].apply(parse_cn_details)
    cn_extracted = pd.DataFrame(cn_details.tolist(), index=df_long.index, columns=['PhÃ²ng SHCN', 'GiÃ¡o viÃªn CN', 'Lá»›p VHPT'])

    df_final = pd.concat([df_long[['Thá»©', 'Buá»•i', 'Tiáº¿t']].reset_index(drop=True), lop_extracted.reset_index(drop=True), cn_extracted.reset_index(drop=True), mh_extracted.reset_index(drop=True)], axis=1)
    df_final['TrÃ¬nh Ä‘á»™'] = df_final['Lá»›p'].apply(lambda x: 'Cao Ä‘áº³ng' if 'C.' in str(x) else ('Trung Cáº¥p' if 'T.' in str(x) else ''))
    df_final.fillna('', inplace=True)

    if teacher_mapping:
        df_final['GiÃ¡o viÃªn CN'] = df_final['GiÃ¡o viÃªn CN'].apply(lambda n: map_and_prefix_teacher_name(n, teacher_mapping))
        df_final['GiÃ¡o viÃªn BM'] = df_final['GiÃ¡o viÃªn BM'].apply(lambda n: map_and_prefix_teacher_name(n, teacher_mapping))
    
    final_cols = ['Thá»©', 'Buá»•i', 'Tiáº¿t', 'Lá»›p', 'SÄ© sá»‘', 'TrÃ¬nh Ä‘á»™', 'MÃ´n há»c', 'PhÃ²ng há»c', 'GiÃ¡o viÃªn BM', 'PhÃ²ng SHCN', 'GiÃ¡o viÃªn CN', 'Lá»›p VHPT', 'Ghi chÃº', 'KHOA', 'NgÃ y Ã¡p dá»¥ng']
    df_final['KHOA'] = '' 
    df_final['NgÃ y Ã¡p dá»¥ng'] = ngay_ap_dung
    return df_final[final_cols]

# --- HÃ€M HIá»‚N THá»Š GIAO DIá»†N TRA Cá»¨U ---
def display_schedule_interface(df_data):
    if df_data.empty:
        st.info("ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘á»ƒ tra cá»©u."); return

    st.header("ğŸ” Tra cá»©u Thá»i KhÃ³a Biá»ƒu")
    class_list = sorted(df_data['Lá»›p'].unique())
    selected_class = st.selectbox("Chá»n lá»›p Ä‘á»ƒ xem chi tiáº¿t:", options=class_list)

    if selected_class:
        class_schedule = df_data[df_data['Lá»›p'] == selected_class].copy()
        
        st.markdown("##### ğŸ“ ThÃ´ng tin chung cá»§a lá»›p")
        info = class_schedule.iloc[0]
        green_color = "#00FF00"
        
        gvcn_val, trinhdo_val, siso_val, psh_val = info.get("GiÃ¡o viÃªn CN") or "ChÆ°a cÃ³", info.get("TrÃ¬nh Ä‘á»™") or "ChÆ°a cÃ³", str(info.get("SÄ© sá»‘") or "N/A"), info.get("PhÃ²ng SHCN") or "ChÆ°a cÃ³"
        gvcn_part = f"ğŸ‘¨â€ğŸ« **Chá»§ nhiá»‡m:** <span style='color:{green_color};'>{gvcn_val}</span>"
        trinhdo_part = f"ğŸ–ï¸ **TrÃ¬nh Ä‘á»™:** <span style='color:{green_color};'>{trinhdo_val}</span>"
        siso_part = f"ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ **SÄ© sá»‘:** <span style='color:{green_color};'>{siso_val}</span>"
        psh_part = f"ğŸ¤ **P.sinh hoáº¡t:** <span style='color:{green_color};'>{psh_val}</span>"
        st.markdown(f"{gvcn_part}&nbsp;&nbsp;&nbsp;&nbsp;{trinhdo_part}&nbsp;&nbsp;&nbsp;&nbsp;{siso_part}&nbsp;&nbsp;&nbsp;&nbsp;{psh_part}", unsafe_allow_html=True)

        st.markdown("--- \n ##### ğŸ—“ï¸ Lá»‹ch há»c chi tiáº¿t")

        number_to_day_map = {2: 'THá»¨ HAI', 3: 'THá»¨ BA', 4: 'THá»¨ TÆ¯', 5: 'THá»¨ NÄ‚M', 6: 'THá»¨ SÃU', 7: 'THá»¨ Báº¢Y'}
        class_schedule['Thá»© Äáº§y Äá»§'] = class_schedule['Thá»©'].map(number_to_day_map)
        
        day_order = list(number_to_day_map.values()); session_order = ['SÃ¡ng', 'Chiá»u']
        class_schedule['Thá»© Äáº§y Äá»§'] = pd.Categorical(class_schedule['Thá»© Äáº§y Äá»§'], categories=day_order, ordered=True)
        class_schedule['Buá»•i'] = pd.Categorical(class_schedule['Buá»•i'], categories=session_order, ordered=True)
        class_schedule_sorted = class_schedule.sort_values(by=['Thá»© Äáº§y Äá»§', 'Buá»•i', 'Tiáº¿t'])

        for day, day_group in class_schedule_sorted.groupby('Thá»© Äáº§y Äá»§', observed=False):
            with st.expander(f"**{day}**"):
                can_consolidate = False
                if set(day_group['Buá»•i'].unique()) == {'SÃ¡ng', 'Chiá»u'}:
                    sang_subjects = day_group[day_group['Buá»•i'] == 'SÃ¡ng'][['MÃ´n há»c', 'GiÃ¡o viÃªn BM', 'PhÃ²ng há»c']].drop_duplicates()
                    chieu_subjects = day_group[day_group['Buá»•i'] == 'Chiá»u'][['MÃ´n há»c', 'GiÃ¡o viÃªn BM', 'PhÃ²ng há»c']].drop_duplicates()
                    if len(sang_subjects) == 1 and sang_subjects.equals(chieu_subjects): can_consolidate = True

                if can_consolidate:
                    col1, col2 = st.columns([1, 6])
                    with col1: st.markdown(f'<p style="color:#17a2b8; font-weight:bold;">Cáº¢ NGÃ€Y</p>', unsafe_allow_html=True)
                    with col2:
                        subject_info = sang_subjects.iloc[0]
                        tiet_str = ", ".join(sorted(day_group['Tiáº¿t'].astype(str).tolist(), key=int))
                        tiet_part = f"â° **Tiáº¿t:** <span style='color:{green_color};'>{tiet_str}</span>"
                        subject_part = f"ğŸ“– **MÃ´n:** <span style='color:{green_color};'>{subject_info['MÃ´n há»c']}</span>"
                        gv_part = f"ğŸ§‘â€ğŸ’¼ **GV:** <span style='color:{green_color};'>{subject_info['GiÃ¡o viÃªn BM']}</span>" if subject_info['GiÃ¡o viÃªn BM'] else ""
                        phong_part = f"ğŸ¤ **PhÃ²ng:** <span style='color:{green_color};'>{subject_info['PhÃ²ng há»c']}</span>" if subject_info['PhÃ²ng há»c'] else ""
                        all_parts = [p for p in [tiet_part, subject_part, gv_part, phong_part] if p]
                        st.markdown("&nbsp;&nbsp;".join(all_parts), unsafe_allow_html=True)
                else:
                    for session, session_group in day_group.groupby('Buá»•i', observed=False):
                        if session_group.empty: continue
                        col1, col2 = st.columns([1, 6])
                        with col1:
                            color = "#28a745" if session == "SÃ¡ng" else "#dc3545"
                            st.markdown(f'<p style="color:{color}; font-weight:bold;">{session.upper()}</p>', unsafe_allow_html=True)
                        with col2:
                            subjects_in_session = {}
                            for _, row in session_group.iterrows():
                                if pd.notna(row['MÃ´n há»c']) and row['MÃ´n há»c'].strip():
                                    key = (row['MÃ´n há»c'], row['GiÃ¡o viÃªn BM'], row['PhÃ²ng há»c'], row['Ghi chÃº'])
                                    if key not in subjects_in_session: subjects_in_session[key] = []
                                    subjects_in_session[key].append(str(row['Tiáº¿t']))
                            if not subjects_in_session:
                                st.markdown("âœ¨Nghá»‰")
                            else:
                                for (subject, gv, phong, ghi_chu), tiet_list in subjects_in_session.items():
                                    tiet_str = ", ".join(sorted(tiet_list, key=int))
                                    tiet_part = f"â° **Tiáº¿t:** <span style='color:{green_color};'>{tiet_str}</span>"
                                    subject_part = f"ğŸ“– **MÃ´n:** <span style='color:{green_color};'>{subject}</span>"
                                    gv_part = f"ğŸ§‘â€ğŸ’¼ **GV:** <span style='color:{green_color};'>{gv}</span>" if gv else ""
                                    phong_part = f"ğŸ¤ **PhÃ²ng:** <span style='color:{green_color};'>{phong}</span>" if phong else ""
                                    ghi_chu_part = ""
                                    if ghi_chu and ghi_chu.strip():
                                        date_match = re.search(r'(\d+/\d+)', ghi_chu)
                                        if date_match:
                                            ghi_chu_part = f"ğŸ”œ **Báº¯t Ä‘áº§u há»c tá»«:** <span style='color:{green_color};'>\"{date_match.group(1)}\"</span>"
                                    all_parts = [p for p in [tiet_part, subject_part, gv_part, phong_part, ghi_chu_part] if p]
                                    st.markdown("&nbsp;&nbsp;".join(all_parts), unsafe_allow_html=True)

        with st.expander("Xem báº£ng dá»¯ liá»‡u chi tiáº¿t cá»§a lá»›p"):
            display_columns = ['Thá»©', 'Buá»•i', 'Tiáº¿t', 'MÃ´n há»c', 'PhÃ²ng há»c', 'GiÃ¡o viÃªn BM', 'Ghi chÃº']
            st.dataframe(class_schedule_sorted[display_columns], use_container_width=True, hide_index=True)

# --- Giao diá»‡n chÃ­nh cá»§a á»©ng dá»¥ng Streamlit ---

st.set_page_config(page_title="TrÃ­ch xuáº¥t vÃ  Truy váº¥n TKB", layout="wide")
st.title("ğŸ“Š TrÃ­ch xuáº¥t, Tra cá»©u vÃ  LÆ°u trá»¯ Thá»i KhÃ³a Biá»ƒu")

TEACHER_INFO_SHEET_ID = "1TJfaywQM1VNGjDbWyC3osTLLOvlgzP0-bQjz8J-_BoI"
teacher_mapping_data = {}
gsheet_client = None
if "gcp_service_account" in st.secrets:
    gsheet_client = connect_to_gsheet()
    if gsheet_client:
        teacher_mapping_data = get_teacher_mapping(gsheet_client, TEACHER_INFO_SHEET_ID)
else:
    st.warning("KhÃ´ng tÃ¬m tháº¥y cáº¥u hÃ¬nh Google Sheets trong `st.secrets`. CÃ¡c tÃ­nh nÄƒng liÃªn quan sáº½ bá»‹ vÃ´ hiá»‡u hÃ³a.", icon="âš ï¸")

tab1, tab2 = st.tabs(["Tra cá»©u TKB tá»« Google Sheet", "Táº£i lÃªn & Xá»­ lÃ½ TKB tá»« Excel"])

with tab1:
    st.header("Tra cá»©u trá»±c tiáº¿p tá»« Google Sheet")
    if gsheet_client:
        sheet_list = get_all_data_sheets(gsheet_client, TEACHER_INFO_SHEET_ID)
        if sheet_list:
            selected_sheet = st.selectbox("Chá»n bá»™ dá»¯ liá»‡u TKB Ä‘á»ƒ tra cá»©u:", options=sheet_list)
            if selected_sheet:
                with st.spinner(f"Äang táº£i dá»¯ liá»‡u tá»« sheet '{selected_sheet}'..."):
                    df_from_gsheet = load_data_from_gsheet(gsheet_client, TEACHER_INFO_SHEET_ID, selected_sheet)
                if not df_from_gsheet.empty:
                    display_schedule_interface(df_from_gsheet)
        else:
            st.info("ChÆ°a cÃ³ dá»¯ liá»‡u TKB nÃ o Ä‘Æ°á»£c lÆ°u trÃªn Google Sheet.")
    else:
        st.error("ChÆ°a káº¿t ná»‘i Ä‘Æ°á»£c vá»›i Google Sheets. Vui lÃ²ng kiá»ƒm tra láº¡i cáº¥u hÃ¬nh `secrets.toml`.")

with tab2:
    st.header("Táº£i lÃªn vÃ  xá»­ lÃ½ file Excel má»›i")
    uploaded_file = st.file_uploader("Chá»n file Excel TKB cá»§a báº¡n", type=["xlsx"])

    if uploaded_file:
        try:
            workbook = openpyxl.load_workbook(io.BytesIO(uploaded_file.getvalue()), data_only=True)
            with st.spinner("Äang xá»­ lÃ½ dá»¯ liá»‡u tá»« file Excel..."):
                raw_df, ngay_ap_dung = extract_schedule_from_excel(workbook.active)
            if raw_df is not None:
                db_df = transform_to_database_format(raw_df, teacher_mapping_data, ngay_ap_dung)
                st.success("Xá»­ lÃ½ file Excel thÃ nh cÃ´ng!")
                if ngay_ap_dung:
                    st.info(f"ÄÃ£ tÃ¬m tháº¥y ngÃ y Ã¡p dá»¥ng trong file: **{ngay_ap_dung}**")
                
                st.markdown("---")
                st.subheader("ğŸ“¤ LÆ°u trá»¯ dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½")
                st.info(f"Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c lÆ°u vÃ o Google Sheet cÃ³ ID: **{TEACHER_INFO_SHEET_ID}**")

                col1, col2, col3, col4 = st.columns(4)
                with col1: nam_hoc = st.text_input("NÄƒm há»c:", value="2425", key="nh")
                with col2: hoc_ky = st.text_input("Há»c ká»³:", value="HK1", key="hk")
                with col3: giai_doan = st.text_input("Giai Ä‘oáº¡n:", value="GD1", key="gd")
                with col4:
                    khoa_list = get_khoa_list(gsheet_client, TEACHER_INFO_SHEET_ID)
                    khoa = st.selectbox("Khoa:", options=khoa_list, key="khoa", help="Danh sÃ¡ch Ä‘Æ°á»£c láº¥y tá»« sheet DANH_MUC")

                sheet_name = f"DATA_{nam_hoc}_{hoc_ky}_{giai_doan}"
                st.write(f"TÃªn sheet sáº½ Ä‘Æ°á»£c táº¡o/cáº­p nháº­t lÃ : **{sheet_name}**")

                if st.button("LÆ°u vÃ o Google Sheet", key="save_button"):
                    if gsheet_client and khoa:
                        with st.spinner(f"Äang cáº­p nháº­t dá»¯ liá»‡u cho khoa '{khoa}'..."):
                            db_df['KHOA'] = khoa
                            success, error_message = update_gsheet_by_khoa(gsheet_client, TEACHER_INFO_SHEET_ID, sheet_name, db_df, khoa)
                            if success:
                                st.success(f"Cáº­p nháº­t dá»¯ liá»‡u thÃ nh cÃ´ng! Báº¡n cÃ³ thá»ƒ qua tab 'Tra cá»©u' Ä‘á»ƒ xem.")
                                st.cache_data.clear()
                            else:
                                st.error(f"Lá»—i khi lÆ°u: {error_message}")
                    else:
                        st.error("KhÃ´ng thá»ƒ lÆ°u. Vui lÃ²ng chá»n má»™t Khoa vÃ  Ä‘áº£m báº£o Ä‘Ã£ káº¿t ná»‘i Google Sheets.")
                
                with st.expander("Xem trÆ°á»›c dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½"):
                    st.dataframe(db_df)
            else:
                st.warning("KhÃ´ng thá»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« file Excel.")
        except Exception as e:
            st.error(f"ÄÃ£ cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ file: {e}")
