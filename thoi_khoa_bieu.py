# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
import streamlit as st
import pandas as pd
import openpyxl
import io
import re
import gspread
from google.oauth2.service_account import Credentials

# --- C√ÅC H√ÄM K·∫æT N·ªêI GOOGLE SHEETS ---

# S·ª≠ d·ª•ng cache_resource ƒë·ªÉ ch·ªâ k·∫øt n·ªëi m·ªôt l·∫ßn
@st.cache_resource
def connect_to_gsheet():
    """
    K·∫øt n·ªëi t·ªõi Google Sheets s·ª≠ d·ª•ng Service Account credentials t·ª´ st.secrets.
    """
    try:
        creds_dict = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi Google Sheets: {e}")
        st.info("Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒë√£ c·∫•u h√¨nh 'gcp_service_account' trong st.secrets.")
        return None

# S·ª≠ d·ª•ng cache_data ƒë·ªÉ cache d·ªØ li·ªáu tr·∫£ v·ªÅ
@st.cache_data(ttl=600) # Cache d·ªØ li·ªáu trong 10 ph√∫t
def get_teacher_mapping(_gsheet_client, spreadsheet_id):
    """
    L·∫•y d·ªØ li·ªáu √°nh x·∫° t√™n gi√°o vi√™n t·ª´ Google Sheet v√† t·∫°o m·ªôt dictionary.
    """
    if _gsheet_client is None:
        return {}
    try:
        spreadsheet = _gsheet_client.open_by_key(spreadsheet_id)
        worksheet = spreadsheet.worksheet("THONG_TIN_GV")
        df = pd.DataFrame(worksheet.get_all_records())
        
        # *** KI·ªÇM TRA L·ªñI CHI TI·∫æT H∆†N ***
        required_cols = ["Ten_viet_tat", "Ho_ten_gv"]
        actual_cols = df.columns.tolist()
        
        missing_cols = [col for col in required_cols if col not in actual_cols]
        
        if missing_cols:
            st.error(f"L·ªói: Sheet 'THONG_TIN_GV' b·ªã thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}.")
            st.info(f"C√°c c·ªôt hi·ªán c√≥ trong sheet l√†: {', '.join(actual_cols)}")
            st.warning("Vui l√≤ng ki·ªÉm tra l·∫°i t√™n c·ªôt trong file Google Sheet c·ªßa b·∫°n (l∆∞u √Ω c·∫£ kho·∫£ng tr·∫Øng v√† vi·∫øt hoa/th∆∞·ªùng).")
            return {}
            
        # T·∫°o m·ªôt dictionary, ƒë·∫£m b·∫£o key (t√™n vi·∫øt t·∫Øt) ƒë∆∞·ª£c x√≥a kho·∫£ng tr·∫Øng
        mapping = pd.Series(df.Ho_ten_gv.values, index=df.Ten_viet_tat.str.strip()).to_dict()
        return mapping
    except gspread.exceptions.WorksheetNotFound:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y sheet c√≥ t√™n 'THONG_TIN_GV' trong file Google Sheet.")
        return {}
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i b·∫£n ƒë·ªì t√™n gi√°o vi√™n t·ª´ Google Sheet: {e}")
        return {}

# --- C√ÅC H√ÄM X·ª¨ L√ù EXCEL ---

def extract_schedule_from_excel(worksheet):
    """
    Tr√≠ch xu·∫•t d·ªØ li·ªáu TKB t·ª´ m·ªôt worksheet, t·ª± ƒë·ªông t√¨m v√πng d·ªØ li·ªáu, 
    x·ª≠ l√Ω √¥ g·ªôp v√† x·ª≠ l√Ω ti√™u ƒë·ªÅ ƒëa d√≤ng.
    """
    
    # --- B∆∞·ªõc 1: T√¨m ƒëi·ªÉm b·∫Øt ƒë·∫ßu c·ªßa b·∫£ng d·ªØ li·ªáu (√¥ ch·ª©a "Th·ª©") ---
    start_row, start_col = -1, -1
    for r_idx, row in enumerate(worksheet.iter_rows(min_row=1, max_row=10), 1):
        for c_idx, cell in enumerate(row, 1):
            if cell.value and "th·ª©" in str(cell.value).lower():
                start_row, start_col = r_idx, c_idx
                break
        if start_row != -1:
            break
            
    if start_row == -1:
        st.error("Kh√¥ng t√¨m th·∫•y √¥ ti√™u ƒë·ªÅ 'Th·ª©' trong 10 d√≤ng ƒë·∫ßu ti√™n c·ªßa file.")
        return None

    # --- B∆∞·ªõc 2: T√¨m ƒëi·ªÉm k·∫øt th√∫c c·ªßa b·∫£ng d·ªØ li·ªáu ---
    last_row = start_row
    tiet_col_index = start_col + 2 
    for r_idx in range(worksheet.max_row, start_row - 1, -1):
        cell_value = worksheet.cell(row=r_idx, column=tiet_col_index).value
        if cell_value is not None and isinstance(cell_value, (int, float)):
            last_row = r_idx
            break

    last_col = start_col
    for row in worksheet.iter_rows(min_row=start_row, max_row=last_row):
        for cell in row:
            if cell.value is not None and cell.column > last_col:
                last_col = cell.column

    # --- B∆∞·ªõc 3: X·ª≠ l√Ω c√°c √¥ b·ªã g·ªôp (merged cells) ---
    merged_values = {}
    for merged_range in worksheet.merged_cells.ranges:
        top_left_cell = worksheet.cell(row=merged_range.min_row, column=merged_range.min_col)
        for row in range(merged_range.min_row, merged_range.max_row + 1):
            for col in range(merged_range.min_col, merged_range.max_col + 1):
                merged_values[(row, col)] = top_left_cell.value

    # --- B∆∞·ªõc 4: ƒê·ªçc d·ªØ li·ªáu v√†o m·ªôt danh s√°ch 2D, √°p d·ª•ng gi√° tr·ªã t·ª´ √¥ g·ªôp ---
    day_to_number_map = {'HAI': 2, 'BA': 3, 'T∆Ø': 4, 'NƒÇM': 5, 'S√ÅU': 6, 'B·∫¢Y': 7}
    data = []
    # ƒê·ªçc t·ª´ d√≤ng ti√™u ƒë·ªÅ ƒë·∫ßu ti√™n ƒë·ªÉ bao g·ªìm c·∫£ 2 d√≤ng header
    for r_idx in range(start_row, last_row + 1):
        row_data = []
        for c_idx in range(start_col, last_col + 1):
            cell_value = None
            if (r_idx, c_idx) in merged_values:
                cell_value = merged_values[(r_idx, c_idx)]
            else:
                cell_value = worksheet.cell(row=r_idx, column=c_idx).value
            
            # *** S·ª¨A L·ªñI: Chu·∫©n h√≥a c·ªôt "Th·ª©" th√†nh s·ªë ***
            if c_idx == start_col and r_idx > start_row: # Ch·ªâ x·ª≠ l√Ω c√°c d√≤ng d·ªØ li·ªáu, b·ªè qua header
                clean_day = re.sub(r'\s+', '', str(cell_value or '')).strip().upper()
                cell_value = day_to_number_map.get(clean_day, cell_value) # Chuy·ªÉn sang s·ªë, n·∫øu kh√¥ng kh·ªõp th√¨ gi·ªØ nguy√™n

            row_data.append(cell_value)
        data.append(row_data)

    if not data:
        return None

    # --- B∆∞·ªõc 5: X·ª≠ l√Ω ti√™u ƒë·ªÅ ƒëa d√≤ng v√† t·∫°o DataFrame ---
    header_level1 = data[0]
    header_level2 = data[1]
    
    # ƒêi·ªÅn c√°c gi√° tr·ªã b·ªã thi·∫øu trong header c·∫•p 1 (do g·ªôp √¥)
    filled_header_level1 = []
    last_val = ""
    for val in header_level1:
        if val is not None and str(val).strip() != '':
            last_val = val
        filled_header_level1.append(last_val)

    # K·∫øt h·ª£p 2 d√≤ng ti√™u ƒë·ªÅ th√†nh m·ªôt, d√πng k√Ω t·ª± ƒë·∫∑c bi·ªát ƒë·ªÉ sau n√†y t√°ch ra
    combined_headers = []
    for i in range(len(filled_header_level1)):
        h1 = str(filled_header_level1[i] or '').strip()
        h2 = str(header_level2[i] or '').strip()
        # ƒê·ªëi v·ªõi c√°c c·ªôt l·ªõp h·ªçc, k·∫øt h·ª£p c·∫£ 2 d√≤ng. C√°c c·ªôt kh√°c gi·ªØ nguy√™n.
        if i >= 3: # Gi·∫£ ƒë·ªãnh c√°c c·ªôt l·ªõp h·ªçc b·∫Øt ƒë·∫ßu t·ª´ c·ªôt th·ª© 4
             combined_headers.append(f"{h1}___{h2}")
        else:
             combined_headers.append(h1)

    # D·ªØ li·ªáu th·ª±c t·∫ø b·∫Øt ƒë·∫ßu t·ª´ d√≤ng th·ª© 3 (index 2)
    actual_data = data[2:]
    
    df = pd.DataFrame(actual_data, columns=combined_headers)
    
    return df

def map_and_prefix_teacher_name(short_name, mapping):
    """
    √Ånh x·∫° t√™n vi·∫øt t·∫Øt sang t√™n ƒë·∫ßy ƒë·ªß v√† th√™m ti·ªÅn t·ªë 'Th·∫ßy'/'C√¥'.
    """
    # ƒê·∫£m b·∫£o short_name l√† m·ªôt chu·ªói v√† ƒë√£ ƒë∆∞·ª£c x√≥a kho·∫£ng tr·∫Øng
    short_name_clean = str(short_name or '').strip()
    
    # N·∫øu t√™n tr·ªëng, tr·∫£ v·ªÅ chu·ªói r·ªóng
    if not short_name_clean:
        return ''
        
    # T√¨m t√™n ƒë·∫ßy ƒë·ªß trong dictionary √°nh x·∫°
    full_name = mapping.get(short_name_clean)
    
    if full_name:
        # N·∫øu t√¨m th·∫•y, th√™m ti·ªÅn t·ªë ph√π h·ª£p
        if short_name_clean.startswith('T.'):
            return f"Th·∫ßy {full_name}"
        elif short_name_clean.startswith('C.'):
            return f"C√¥ {full_name}"
        else:
            # N·∫øu kh√¥ng c√≥ ti·ªÅn t·ªë, tr·∫£ v·ªÅ t√™n ƒë·∫ßy ƒë·ªß
            return full_name
    else:
        # N·∫øu kh√¥ng t√¨m th·∫•y, tr·∫£ v·ªÅ t√™n vi·∫øt t·∫Øt g·ªëc
        return short_name_clean

def transform_to_database_format(df_wide, teacher_mapping):
    """
    Chuy·ªÉn ƒë·ªïi DataFrame d·∫°ng r·ªông (wide) sang d·∫°ng d√†i (long) v√† t√°ch th√¥ng tin chi ti·∫øt.
    """
    id_vars = ['Th·ª©', 'Bu·ªïi', 'Ti·∫øt']
    
    # Chuy·ªÉn ƒë·ªïi t·ª´ d·∫°ng r·ªông sang d·∫°ng d√†i
    df_long = pd.melt(df_wide, id_vars=id_vars, var_name='L·ªõp_Raw', value_name='Chi ti·∫øt M√¥n h·ªçc')
    
    # L√†m s·∫°ch d·ªØ li·ªáu ban ƒë·∫ßu
    df_long.dropna(subset=['Chi ti·∫øt M√¥n h·ªçc'], inplace=True)
    df_long = df_long[df_long['Chi ti·∫øt M√¥n h·ªçc'].astype(str).str.strip() != '']
    
    # --- T√ÅCH D·ªÆ LI·ªÜU T·ª™ TI√äU ƒê·ªÄ (L·ªõp_Raw) ---
    header_parts = df_long['L·ªõp_Raw'].str.split('___', expand=True)
    
    # T√°ch L·ªõp v√† Sƒ© s·ªë t·ª´ ph·∫ßn 1
    lop_pattern = re.compile(r'^(.*?)\s*(?:\((\d+)\))?$') # Sƒ© s·ªë l√† t√πy ch·ªçn
    lop_extracted = header_parts[0].str.extract(lop_pattern)
    lop_extracted.columns = ['L·ªõp', 'Sƒ© s·ªë']

    # T√°ch th√¥ng tin ch·ªß nhi·ªám t·ª´ ph·∫ßn 2 (linh ho·∫°t h∆°n)
    cn_pattern = re.compile(r'^(.*?)\s*-\s*(.*?)(?:\s*\((.*?)\))?$') # L·ªõp VHPT l√† t√πy ch·ªçn
    cn_extracted = header_parts[1].str.extract(cn_pattern)
    cn_extracted.columns = ['Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 'L·ªõp VHPT']
    
    # --- T√ÅCH D·ªÆ LI·ªÜU T·ª™ N·ªòI DUNG √î (Chi ti·∫øt M√¥n h·ªçc) ---
    mh_pattern = re.compile(r'^(.*?)\s*\((.*?)\s*-\s*(.*?)\)$')
    mh_extracted = df_long['Chi ti·∫øt M√¥n h·ªçc'].astype(str).str.extract(mh_pattern)
    mh_extracted.columns = ['M√¥n h·ªçc T√°ch', 'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM']

    # Gh√©p t·∫•t c·∫£ c√°c ph·∫ßn ƒë√£ t√°ch v√†o DataFrame ch√≠nh
    df_final = pd.concat([
        df_long[['Th·ª©', 'Bu·ªïi', 'Ti·∫øt']].reset_index(drop=True), 
        lop_extracted.reset_index(drop=True),
        cn_extracted.reset_index(drop=True), 
        mh_extracted.reset_index(drop=True),
        df_long[['Chi ti·∫øt M√¥n h·ªçc']].reset_index(drop=True)
    ], axis=1)

    # --- T·∫†O C√ÅC C·ªòT CU·ªêI C√ôNG ---
    # C·ªôt M√¥n h·ªçc
    df_final['M√¥n h·ªçc'] = df_final['M√¥n h·ªçc T√°ch'].fillna(df_final['Chi ti·∫øt M√¥n h·ªçc'])
    
    # C·ªôt Tr√¨nh ƒë·ªô
    def get_trinh_do(class_name):
        if 'C.' in str(class_name):
            return 'Cao ƒë·∫≥ng'
        if 'T.' in str(class_name):
            return 'Trung C·∫•p'
        return ''
    df_final['Tr√¨nh ƒë·ªô'] = df_final['L·ªõp'].apply(get_trinh_do)

    # *** √ÅNH X·∫† T√äN GI√ÅO VI√äN ***
    if teacher_mapping:
        df_final['Gi√°o vi√™n CN'] = df_final['Gi√°o vi√™n CN'].apply(lambda name: map_and_prefix_teacher_name(name, teacher_mapping))
        df_final['Gi√°o vi√™n BM'] = df_final['Gi√°o vi√™n BM'].apply(lambda name: map_and_prefix_teacher_name(name, teacher_mapping))
    
    # S·∫Øp x·∫øp v√† ch·ªçn c√°c c·ªôt c·∫ßn thi·∫øt
    final_cols = [
        'Th·ª©', 'Bu·ªïi', 'Ti·∫øt', 'L·ªõp', 'Sƒ© s·ªë', 'Tr√¨nh ƒë·ªô', 'M√¥n h·ªçc', 
        'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 'Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 'L·ªõp VHPT'
    ]
    df_final = df_final[final_cols]
    
    # ƒêi·ªÅn gi√° tr·ªã r·ªóng cho c√°c √¥ kh√¥ng c√≥ d·ªØ li·ªáu
    df_final.fillna('', inplace=True)
    
    return df_final

def generate_schedule_summary(schedule_df):
    """
    T·∫°o m·ªôt b·∫£n t√≥m t·∫Øt/di·ªÖn gi·∫£i th·ªùi kh√≥a bi·ªÉu t·ª´ DataFrame.
    Gom nh√≥m theo C·∫•p b·∫≠c:
        C·∫•p 1: Th·ª© (ƒë∆∞·ª£c s·∫Øp x·∫øp ƒë√∫ng th·ª© t·ª±)
        C·∫•p 2: Bu·ªïi (S√°ng, Chi·ªÅu)
        C·∫•p 3: M√¥n h·ªçc (bao g·ªìm th√¥ng tin chi ti·∫øt)
    """
    if schedule_df.empty:
        return "Kh√¥ng c√≥ d·ªØ li·ªáu th·ªùi kh√≥a bi·ªÉu ƒë·ªÉ hi·ªÉn th·ªã."

    # T·∫°o m·ªôt b·∫£n sao ƒë·ªÉ tr√°nh SettingWithCopyWarning
    schedule_df = schedule_df.copy()

    # 1. Chu·∫©n h√≥a v√† S·∫Øp x·∫øp
    # ƒê·ªãnh nghƒ©a th·ª© t·ª± ƒë√∫ng c·ªßa c√°c ng√†y trong tu·∫ßn
    day_mapping = {
        'TH·ª® HAI': 2, 'TH·ª® BA': 3, 'TH·ª® T∆Ø': 4,
        'TH·ª® NƒÇM': 5, 'TH·ª® S√ÅU': 6, 'TH·ª® B·∫¢Y': 7, 'CH·ª¶ NH·∫¨T': 1
    }
    # T·∫°o c·ªôt s·ªë ƒë·ªÉ s·∫Øp x·∫øp v√† chuy·ªÉn 'Th·ª©' v·ªÅ ch·ªØ IN HOA ƒë·ªÉ ƒë·ªìng b·ªô
    schedule_df['Th·ª© Num'] = schedule_df['Th·ª©'].str.upper().map(day_mapping)
    
    # S·∫Øp x·∫øp theo Th·ª© -> Bu·ªïi -> Ti·∫øt
    schedule_df_sorted = schedule_df.sort_values(by=['Th·ª© Num', 'Bu·ªïi', 'Ti·∫øt'])

    summary_lines = ["### T√≥m T·∫Øt Th·ªùi Kh√≥a Bi·ªÉu üìù", ""]
    
    # 2. Gom nh√≥m theo C·∫•p 1: Th·ª©
    # D√πng groupby().groups.keys() ƒë·ªÉ gi·ªØ l·∫°i th·ª© t·ª± ƒë√£ s·∫Øp x·∫øp
    for day in schedule_df_sorted.groupby('Th·ª©', sort=False).groups.keys():
        day_group = schedule_df_sorted[schedule_df_sorted['Th·ª©'] == day]
        summary_lines.append(f"**üóìÔ∏è {day.upper()}**")
        
        # 3. Gom nh√≥m theo C·∫•p 2: Bu·ªïi
        for session in day_group['Bu·ªïi'].unique():
            summary_lines.append(f"&nbsp;&nbsp;&nbsp; bu·ªïi **{session}:**")
            session_group = day_group[day_group['Bu·ªïi'] == session]
            
            # 4. Gom nh√≥m theo C·∫•p 3: M√¥n h·ªçc v√† t·ªïng h·ª£p th√¥ng tin
            # S·ª≠ d·ª•ng dict ƒë·ªÉ gom c√°c ti·∫øt, gi√°o vi√™n, ph√≤ng h·ªçc c·ªßa c√πng 1 m√¥n
            subjects_in_session = {}
            for _, row in session_group.iterrows():
                subject = row['M√¥n h·ªçc']
                # B·ªè qua c√°c d√≤ng kh√¥ng c√≥ t√™n m√¥n h·ªçc
                if pd.isna(subject) or str(subject).strip() == "":
                    continue

                if subject not in subjects_in_session:
                    subjects_in_session[subject] = {
                        'Tiet': [],
                        'GiaoVien': set(), # D√πng set ƒë·ªÉ tr√°nh tr√πng l·∫∑p t√™n
                        'PhongHoc': set()  # D√πng set ƒë·ªÉ tr√°nh tr√πng l·∫∑p ph√≤ng
                    }
                
                # Th√™m th√¥ng tin chi ti·∫øt
                subjects_in_session[subject]['Tiet'].append(str(row['Ti·∫øt']))
                if pd.notna(row['Gi√°o vi√™n BM']):
                    subjects_in_session[subject]['GiaoVien'].add(row['Gi√°o vi√™n BM'])
                if pd.notna(row['Ph√≤ng h·ªçc']):
                    subjects_in_session[subject]['PhongHoc'].add(row['Ph√≤ng h·ªçc'])
            
            # 5. ƒê·ªãnh d·∫°ng v√† hi·ªÉn th·ªã th√¥ng tin m√¥n h·ªçc
            if not subjects_in_session:
                summary_lines.append(f"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üîπ *Kh√¥ng c√≥ ti·∫øt h·ªçc*")
            else:
                for subject, details in subjects_in_session.items():
                    tiet_str = ", ".join(sorted(details['Tiet'], key=int))
                    gv_str = ", ".join(sorted(list(details['GiaoVien'])))
                    phong_str = ", ".join(sorted(list(details['PhongHoc'])))
                    
                    summary_lines.append(f"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üîπ **{subject}**:")
                    summary_lines.append(f"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- **Ti·∫øt:** {tiet_str}")
                    if gv_str:
                        summary_lines.append(f"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- **GV:** {gv_str}")
                    if phong_str:
                        summary_lines.append(f"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- **Ph√≤ng:** {phong_str}")
        
        summary_lines.append("") # Th√™m m·ªôt d√≤ng tr·ªëng ƒë·ªÉ ph√¢n c√°ch c√°c ng√†y

    return "\n".join(summary_lines)


# --- Giao di·ªán ·ª©ng d·ª•ng Streamlit ---

st.set_page_config(page_title="Tr√≠ch xu·∫•t v√† Truy v·∫•n TKB", layout="wide")
st.title("üìä Tr√≠ch xu·∫•t v√† Truy v·∫•n Th·ªùi Kh√≥a Bi·ªÉu")
st.write("T·∫£i file Excel TKB, ·ª©ng d·ª•ng s·∫Ω t·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi th√†nh c∆° s·ªü d·ªØ li·ªáu v√† cho ph√©p b·∫°n tra c·ª©u th√¥ng tin chi ti·∫øt.")

# --- H∆Ø·ªöNG D·∫™N C·∫§U H√åNH ---
with st.expander("üí° H∆∞·ªõng d·∫´n c·∫•u h√¨nh ƒë·ªÉ √°nh x·∫° t√™n gi√°o vi√™n"):
    st.info("""
        ƒê·ªÉ ·ª©ng d·ª•ng c√≥ th·ªÉ t·ª± ƒë·ªông chuy·ªÉn t√™n gi√°o vi√™n vi·∫øt t·∫Øt sang t√™n ƒë·∫ßy ƒë·ªß, b·∫°n c·∫ßn:
        1.  **T·∫°o m·ªôt Service Account** tr√™n Google Cloud Platform v√† c·∫•p quy·ªÅn truy c·∫≠p Google Sheets API.
        2.  **Chia s·∫ª file Google Sheet** c√≥ m√£ `1TJfaywQM1VNGjDbWyC3osTLLOvlgzP0-bQjz8J-_BoI` v·ªõi ƒë·ªãa ch·ªâ email c·ªßa Service Account.
        3.  **Th√™m th√¥ng tin credentials** c·ªßa Service Account v√†o `secrets.toml` c·ªßa ·ª©ng d·ª•ng Streamlit theo m·∫´u sau:

        ```toml
        [gcp_service_account]
        type = "service_account"
        project_id = "your-project-id"
        private_key_id = "your-private-key-id"
        private_key = "-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n"
        client_email = "your-service-account-email@...iam.gserviceaccount.com"
        client_id = "your-client-id"
        auth_uri = "[https://accounts.google.com/o/oauth2/auth](https://accounts.google.com/o/oauth2/auth)"
        token_uri = "[https://oauth2.googleapis.com/token](https://oauth2.googleapis.com/token)"
        auth_provider_x509_cert_url = "[https://www.googleapis.com/oauth2/v1/certs](https://www.googleapis.com/oauth2/v1/certs)"
        client_x509_cert_url = "[https://www.googleapis.com/robot/v1/metadata/x509/your-service-account-email](https://www.googleapis.com/robot/v1/metadata/x509/your-service-account-email)..."
        ```
        N·∫øu kh√¥ng c√≥ c·∫•u h√¨nh n√†y, t√™n gi√°o vi√™n s·∫Ω ƒë∆∞·ª£c gi·ªØ nguy√™n ·ªü d·∫°ng vi·∫øt t·∫Øt.
    """)

# --- K·∫æT N·ªêI V√Ä L·∫§Y D·ªÆ LI·ªÜU √ÅNH X·∫† ---
# ID c·ªßa Google Sheet ch·ª©a th√¥ng tin gi√°o vi√™n
TEACHER_INFO_SHEET_ID = "1TJfaywQM1VNGjDbWyC3osTLLOvlgzP0-bQjz8J-_BoI"
teacher_mapping_data = {}
# Ch·ªâ k·∫øt n·ªëi n·∫øu c√≥ secrets ƒë∆∞·ª£c c·∫•u h√¨nh
if "gcp_service_account" in st.secrets:
    gsheet_client = connect_to_gsheet()
    teacher_mapping_data = get_teacher_mapping(gsheet_client, TEACHER_INFO_SHEET_ID)
else:
    st.warning("Kh√¥ng t√¨m th·∫•y c·∫•u h√¨nh Google Sheets trong `st.secrets`. T√™n gi√°o vi√™n s·∫Ω kh√¥ng ƒë∆∞·ª£c √°nh x·∫°.", icon="‚ö†Ô∏è")


uploaded_file = st.file_uploader("Ch·ªçn file Excel c·ªßa b·∫°n", type=["xlsx"])

if uploaded_file is not None:
    try:
        file_bytes = io.BytesIO(uploaded_file.getvalue())
        workbook = openpyxl.load_workbook(file_bytes, data_only=True)
        sheet = workbook.active

        st.success(f"ƒê√£ ƒë·ªçc th√†nh c√¥ng file: **{uploaded_file.name}**")
        
        with st.spinner("ƒêang t√¨m v√† x·ª≠ l√Ω d·ªØ li·ªáu..."):
            raw_df = extract_schedule_from_excel(sheet)

        if raw_df is not None:
            # Truy·ªÅn d·ªØ li·ªáu √°nh x·∫° v√†o h√†m chuy·ªÉn ƒë·ªïi
            db_df = transform_to_database_format(raw_df, teacher_mapping_data)

            if db_df is not None:
                st.markdown("---")
                st.header("üîç Tra c·ª©u Th·ªùi Kh√≥a Bi·ªÉu")
                
                class_list = sorted(db_df['L·ªõp'].unique())
                selected_class = st.selectbox("Ch·ªçn l·ªõp ƒë·ªÉ xem chi ti·∫øt:", options=class_list)

                if selected_class:
                    class_schedule = db_df[db_df['L·ªõp'] == selected_class]
                    
                    # *** T·∫†O V√Ä HI·ªÇN TH·ªä B·∫¢N DI·ªÑN GI·∫¢I ***
                    summary_text = generate_schedule_summary(class_schedule)
                    st.markdown(summary_text)

                    # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu chi ti·∫øt
                    st.write("#### B·∫£ng d·ªØ li·ªáu chi ti·∫øt:")
                    class_schedule_sorted = class_schedule.sort_values(by=['Th·ª©', 'Bu·ªïi', 'Ti·∫øt'])
                    display_columns = [
                        'Th·ª©', 'Bu·ªïi', 'Ti·∫øt', 'M√¥n h·ªçc', 'Ph√≤ng h·ªçc', 'Gi√°o vi√™n BM', 
                        'Sƒ© s·ªë', 'Tr√¨nh ƒë·ªô', 'Ph√≤ng SHCN', 'Gi√°o vi√™n CN', 'L·ªõp VHPT'
                    ]
                    
                    st.dataframe(
                        class_schedule_sorted[display_columns],
                        use_container_width=True,
                        hide_index=True
                    )
                
                with st.expander("Xem to√†n b·ªô d·ªØ li·ªáu d·∫°ng C∆° s·ªü d·ªØ li·ªáu"):
                    st.dataframe(db_df, use_container_width=True, hide_index=True)
            
            with st.expander("Xem d·ªØ li·ªáu g·ªëc (ƒë√£ x·ª≠ l√Ω √¥ g·ªôp v√† ti√™u ƒë·ªÅ)"):
                st.dataframe(raw_df)
        else:
            st.warning("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë·ªãnh d·∫°ng file c·ªßa b·∫°n.")

    except Exception as e:
        st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω file: {e}")
